{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjIELFnOaDSx"
      },
      "source": [
        "# 2025-1 Artificial Intelligence (01)\n",
        "## Homework #3: EN-FR Machine Translation Using LSTM, Attention, and Transformer\n",
        "---\n",
        "Copyright (c) Prof. Jaehyeong Sim\n",
        "\n",
        "Department of Computer Science and Engineering\n",
        "\n",
        "College of Artificial Intelligence\n",
        "\n",
        "Ewha Womans University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZzUEccaIg1"
      },
      "source": [
        "## Guideline\n",
        "### Introduction\n",
        "*   Here in this homework, we will implement a **EN-FR machine translator** in PyTorch using three models: an **LSTM**, an **LSTM with Attention**, a **Transformer**.\n",
        "*   We didn't cover **NLP pipeline** in class, so the code might look complicated. I tried to explain the code as clearly as possible, and if you understand the entire code, you can now understand the basics of NLP pipeline and how the models work. So I **highly recommend you to read the code and the explanation carefully and understand them**.\n",
        "*   The training of each model takes long time (LSTM: 70 min, LSTM w/ attn: 120 min, Transformer: 50 min), so I suggest you start this homework early.\n",
        "\n",
        "### Your job\n",
        "1. Please complete the code. You only have to write the parts marked as **# TODO**.\n",
        "2. Please answer the discussion topics at the bottom of this notebook in a **separate PDF file**.\n",
        "\n",
        "### Submission guide\n",
        "1. Please rename the completed skeleton file to ***STUDENT_ID*.ipynb**. Your own student ID goes to *STUDENT_ID*. For example, if your student ID is 2512345, the file name should be **2512345.ipynb**. Also, make your PDF file name ***STUDENT_ID*.pdf***.\n",
        "2. Make sure that your notebook contains the **output of each cell** including the translation results with your own sentence.\n",
        "3. Turn in them into the Ewha CyberCampus.\n",
        "\n",
        "\n",
        "⚠ If you doesn't follow the submission guide above, you will get **5 point deduction** from this homework score.\n",
        "\n",
        "### Deadline\n",
        "*   **June 4, 23:59**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgaq-Hs1acBU"
      },
      "source": [
        "### 1. Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmKnYj_ttiiy",
        "outputId": "9cbabcd3-7492-431c-90e0-80e92e10ab02"
      },
      "outputs": [],
      "source": [
        "%pip install -Uq \"datasets>=2.19\" \"fsspec>=2023.6.0\" sentencepiece sacrebleu\n",
        "%pip install torchinfo torch numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "36UvS6oXZpvK"
      },
      "outputs": [],
      "source": [
        "import math, random, pathlib, os, time, sentencepiece as spm\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrQWBZshasGx"
      },
      "source": [
        "### 2. Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vrQB72YFWsSD"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "vocab_size = 4000\n",
        "subset_size = 50000\n",
        "max_len = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lZ0tlO0RWsSD"
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "lstm_epochs = 15\n",
        "lstm_layers = 3\n",
        "lstm_hidden = 1024\n",
        "lstm_batch_size = 128\n",
        "lstm_log_interval = 50\n",
        "lstm_dropout = 0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2yZFzAzsauMK"
      },
      "outputs": [],
      "source": [
        "# Transformer\n",
        "trans_base_lr = 5e-4\n",
        "d_model      = 512\n",
        "nhead        = 8\n",
        "nlayers      = 4\n",
        "ffn_dim      = 2048\n",
        "trans_epochs   = 15\n",
        "trans_log_interval = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3y2dU-7a8ak"
      },
      "source": [
        "### 3. Preprocessing\n",
        "Overall flow:\n",
        "\n",
        "\n",
        "```\n",
        "raw text (train.en/fr)\n",
        "↓\n",
        "learn vocab (SentencePieceTrainer)\n",
        "↓\n",
        "text to IDs (encode())\n",
        "↓\n",
        "model (LSTM, Transformer)\n",
        "```\n",
        "\n",
        "1.   Corpus acquisition\n",
        "  *   Goal: obtain a parallel English-French corpus.\n",
        "  *   load_dataset(): Hugging Face Datasets downloads the IWSLT 2017 TED-talk translations and returns a list of dictionaries\n",
        "  *   Having the two languages side by side is what later lets us train a sequence-to-sequence model.\n",
        "\n",
        "2.   Sampling a subset\n",
        "  *   The original machine-translation corpora is big. Shuffling with a fixed seed (42) and picking the first subset_size examples makes experiments reproducible and keeps training time reasonable for Colab GPU (T4).\n",
        "\n",
        "3. Writing raw text files (train.en, train.fr)\n",
        "  *   SentencePiece’s trainer expects one sentence per line of plain text. Saving the sample accomplishes two things:\n",
        "    * Gives SentencePiece its required input format.\n",
        "    * Lets you open the files in a text editor to see the real sentences the model will see.\n",
        "\n",
        "4. Learning a sub-word vocabulary with SentencePiece (BPE)\n",
        "  * What is vocabulary learning?\n",
        "    * Deep learning models consume numbers, not strings. “Vocabulary learning”  decides which text fragments become tokens and assigns each fragment a unique integer ID.\n",
        "    * Classic NLP used a fixed word list. Rare or misspelled words were pushed into a single \\<unk> bucket → information loss.\n",
        "      * \\<unk>: special token for any character sequence not in the learned vocab.\n",
        "    * Today we prefer sub-word units (e.g. Byte-Pair Encoding, WordPiece, Unigram). They split unseen words like:\n",
        "      \n",
        "      *internationalization* (not in vocab) → *international* ##*ization* (both are in vocab)\n",
        "\n",
        "      so the model still sees meaningful pieces and you keep vocabulary size manageable.\n",
        "  * Why sub-words instead of words?\n",
        "    * Open-vocabulary: can spell out the vocabulary it has never seen.\n",
        "    * Keeps vocab_size small so embedding matrices fit in memory.\n",
        "  * The trainer is configured with explicit IDs/pieces for \\<pad>, \\<unk>, \\<s> (BOS), \\</s> (EOS) because your downstream model will need to know exactly which integers correspond to padding, beginnig-of-sentence, etc. Changing them later would silently corrupt training.\n",
        "\n",
        "5. Runtime tokenizer setup\n",
        "  * A SentencePieceProcessor loads the freshly trained bpe.model and exposes:\n",
        "    * encode(str) -> List[int]\n",
        "    * special-token IDs (pad_id(), bos_id(), …)\n",
        "    * total vocabulary size (get_piece_size()).\n",
        "  * The utility encode() function truncates long sentences to max_len-1 tokens and appends an explicit EOS_ID. (RNNs/Transformers work best when they know where to stop decoding.)\n",
        "\n",
        "6. TranslationDataset\n",
        "  * A PyTorch Dataset that lazily keeps the raw strings. We postpone tokenization to the collate step so each mini-batch can be truncated/padded to its own maximum length—this is more memory-efficient than padding everything to a corpus-wide max.\n",
        "\n",
        "7. Mini-batch collation\n",
        "  * collate():\n",
        "    * Tokenizes every (src, tgt) pair with encode().\n",
        "    * Finds the longest sequence length inside that batch.\n",
        "    * Right-pads shorter sequences with \\<pad> so torch.tensor() can stack them into a rectangular batch_size × seq_len tensor.\n",
        "  * The result is two LongTensors ready for nn.Embedding → encoder/decoder → loss calculation.\n",
        "\n",
        "8. DataLoaders\n",
        "  * Train loader pulls 50 000 sentence pairs, shuffles each epoch, and applies our custom padding.\n",
        "  * Validation loader uses a fixed 1 000-sentence slice with deterministic order.\n",
        "  * Both loaders now stream GPU-ready batches you can feed directly into an LSTM or Transformer model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557,
          "referenced_widgets": [
            "30924a03bd6f4beb8bed5fdf95c9a02d",
            "3bddc306544346b2842938fe990059cd",
            "5948a122d30444538e8c17d649510e87",
            "03e3343181314d148ee66c2cfd129a26",
            "36a5b836116b4d8d8874a5ddc02796cb",
            "fb98224f6d7f40ceb9968e9c69c2be6a",
            "87335e7d2dc54dc897cb2bde1c8aecf9",
            "d8330088733e43b1a35896b05e1a8ce6",
            "cb033694dc564b0292ae96d905f7936a",
            "53e016fbc8944b4094abec2124f462e1",
            "c369cf4e9b314582b40b2b025f4dbff5",
            "3a2c1e50fc1849e4b53919f09dee9641",
            "d7cbcb25477a4a9cbd8aaf76337dc418",
            "96933d2827a6488da37e60b40e5c68ea",
            "f00e49e564d34e2197ad793be3e7e932",
            "49ec6d6015464296a6377ce1f03a0548",
            "be7cc6c6817143e1a36431adc6e59515",
            "5db71b45b1b64ecc9d2668c420bab02c",
            "feded37e56694c148b33e60b3000ad0a",
            "d4c750f21fcb4c98918c5600e3148fe3",
            "ad68b86067ea4a7591c42831331f057c",
            "1b4f397d1ac24906861e8c8a673e2557",
            "880cec8ba30d4366b6431575ac0cddcb",
            "8174ffc4ba7f409ebbfc7f1319c6534d",
            "7fa49081e1694cc1960e7c1d2ac2903f",
            "38725e2aacb34142b4cbd774d0a833f3",
            "a617ef701a3e49f4a5c70aa5ea3818df",
            "856b7498bafa420088a71d46db511f36",
            "ae8e28ecb72946bfa43c10337200b541",
            "cf53f6fe1dea49f0be32af13058036e1",
            "d5b5b4b2a6ec4ca6b397cbf83db10b9b",
            "7be37ee9859e4d88b809fa96c89cafb0",
            "f8d7916922804215b0289af0e2211762",
            "77b76e7b2eaa41a09d0a783aba65e094",
            "ff57be8010c544e48efef22204a14272",
            "6dbd54241c7f4de5b36099d315d55fff",
            "c511f4d3a0af44ca9a59600af8f51c12",
            "ec7c0083e3624795b7efadf56aba62c7",
            "3b37175d8ed84687af48311580bbaaae",
            "e171ae98748241708fe219f825257fb8",
            "ca57e7dd6f46414fa1e9eddee2479de7",
            "517fa1176e394fb48eafcc1902f23c2e",
            "61aee6704fb64b538ce6ec7008813ce5",
            "bded9004353647c8bb34a05e3ce9646e",
            "ab640e0a30f74d0c9a9b05136accdb52",
            "a8f4bd66b23a46cdb98749dc523aa66d",
            "f9b8cd753c594427a4a529d37ec0d867",
            "e02ab684e49348478c4ee9c3e3756793",
            "c3aa19cfc7d440bbb394c79a77881257",
            "b7950b3d4e7a445ea24f7fd4f49d91e1",
            "88bc08ab551b4855ad6bf2e89702dfed",
            "9326b805e3d84661a6e2ca260e6a2620",
            "d8b847bb07594782a74372d4a050b1ef",
            "2af494c0c4a443cbb73a8aaba3c6173c",
            "dd7fc2c0f90146d18b03d8451abb765d",
            "7002bfd747ee4ec8a5349e3ce9bd0394",
            "e8f83ee82b174bf399f85c50c97518ba",
            "e4ec61c122ea4975bf66113e0f113d35",
            "730506df741d4370889e79004a0769ff",
            "405994a47270432f938906ce19418f8b",
            "2a430f92e48243fbbaff48a2eaccc64e",
            "4b0c28c42b7b4e598a158c40015c7a43",
            "f5ba4986b3bf4fd7bc46a33419e1eaae",
            "815a63adf5104c4d97037d4d37dfb110",
            "adae496b7890490c9c480281b0620986",
            "06586d26dabb4602aa2a5e4f6f11d125",
            "570ee675b2be46b1a2374e96a70acd13",
            "394b6e018cfe4253a13c3ca702213f75",
            "53a542222f714fab93b7628db0a32d05",
            "aa51544e0eb545089cbb26f2aa3e428d",
            "21e9f6c4f42f40a497c6ffb378e74c21",
            "f07c98d51d2e4469bf46e55b5abb44f4",
            "089f8b753a6245999193083b4f0c62eb",
            "e569187696e54602bc2d4d6e7401a249",
            "7b12dfe652514490840762b6eab6ef02",
            "55c2624e54344e20b573addf3ad08db6",
            "1b9e532e9fe945a0af4dcf5a10cb6ff8",
            "b795e0e446bd47cd8a130c9b0e23d9d5",
            "f3f43949c6ca4c15affd611a77977737",
            "81fcedaf1b56491082add26d5deb2a5e",
            "ebb527fdd1f448f0abfac5be53d8e1ea",
            "3214a443a959453ca5d4f01fa6e9f21a",
            "439cb5b8de14477d9d2ef54d0c87eab5",
            "1ebd2920396242d1b74b86d9af961501",
            "8f6c93dbea3d42d7a64d69dafae2ef29",
            "d05b328c3bee4246a9a8b314ad5c053b",
            "02290cc5d3fa427d959ebaafc3a26ab5",
            "c9efc83274a843ed881e441a7f78437b",
            "b65dc5ed8f8146718296cf94b1ef941d",
            "fe2eb7ab4661409597a6a9a480b203fc",
            "acfd79ed58a048c3ad8bdaa000381ff7",
            "9c5a306fa5804a7db7b4c40e14072f44",
            "33fd73c4887b463eac3e25da0084b113",
            "ef44c969839f49948887aa8e069e73d7",
            "9e9ca9ffcb2b4998a02c37d4fa9d6437",
            "701991fceb6e448c986f2918a9f49a2d",
            "c41cc75cba42410fb0b474efff534442",
            "9b59844aade34471bdda49f7d16c941c",
            "2b380ee21ae94fa1868ca87f68e4cc14"
          ]
        },
        "id": "uzycaZCFa9FT",
        "outputId": "d21e8fbd-4e9e-4d9f-c9bf-2076d74216da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading IWSLT 2017 EN-FR dataset …\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30924a03bd6f4beb8bed5fdf95c9a02d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/18.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a2c1e50fc1849e4b53919f09dee9641",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "iwslt2017.py:   0%|          | 0.00/8.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for IWSLT/iwslt2017 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/IWSLT/iwslt2017.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880cec8ba30d4366b6431575ac0cddcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "en-fr.zip:   0%|          | 0.00/27.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77b76e7b2eaa41a09d0a783aba65e094",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/232825 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab640e0a30f74d0c9a9b05136accdb52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/8597 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7002bfd747ee4ec8a5349e3ce9bd0394",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/890 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SentencePiece …\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "570ee675b2be46b1a2374e96a70acd13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/232825 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b795e0e446bd47cd8a130c9b0e23d9d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/8597 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65dc5ed8f8146718296cf94b1ef941d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/890 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ---------------------------------------------------------------------------\n",
        "# 1.  Corpus acquisition\n",
        "# ---------------------------------------------------------------------------\n",
        "DATA_DIR = pathlib.Path('data') # Directory where all assets will live\n",
        "DATA_DIR.mkdir(exist_ok=True) # Safely create it the first time we run\n",
        "\n",
        "print(\"Downloading IWSLT 2017 EN-FR dataset …\")\n",
        "# `load_dataset` fetches a pre-tokenized parallel corpus of\n",
        "# English (\"en\") and French (\"fr\") sentences.  The corpus ships with\n",
        "# predefined splits (train / validation / test).\n",
        "ds = load_dataset('IWSLT/iwslt2017', # dataset identifier (repo_name/config)\n",
        "                  'iwslt2017-en-fr', # configuration: language pair\n",
        "                  split='train', # which split to load\n",
        "                  cache_dir=DATA_DIR, # store raw data under ./data\n",
        "                  )\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2.  Sampling a manageable subset from the dataset to make training simpler\n",
        "# ---------------------------------------------------------------------------\n",
        "# Shuffling with a fixed seed ensures reproducibility: we always pick the\n",
        "# same sentences each run, making debugging easier.\n",
        "sampled = ds.shuffle(seed=42).select(range(subset_size))\n",
        "\n",
        "# Save raw text copies because SentencePiece expects plain‑text files for\n",
        "# training. These files are also handy for quick inspection with a text\n",
        "# editor.\n",
        "src_path = DATA_DIR/'train.en' # English sentences\n",
        "tgt_path = DATA_DIR/'train.fr' # French  sentences\n",
        "src_sentences = [ex['translation']['en'] for ex in sampled]\n",
        "tgt_sentences = [ex['translation']['fr'] for ex in sampled]\n",
        "src_path.write_text('\\n'.join(src_sentences), encoding='utf-8')\n",
        "tgt_path.write_text('\\n'.join(tgt_sentences), encoding='utf-8')\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3.  Sub‑word vocabulary learning with SentencePiece (BPE)\n",
        "# ---------------------------------------------------------------------------\n",
        "# Why sub‑word? It handles open vocabulary problems (e.g. new place names)\n",
        "# better than word‑level tokenizers while keeping sequence length reasonable.\n",
        "print(\"Training SentencePiece …\")\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input=','.join([str(src_path), str(tgt_path)]), # both languages\n",
        "    model_prefix=str(DATA_DIR/'bpe'), # outputs bpe.model / bpe.vocab\n",
        "    vocab_size=vocab_size,\n",
        "    # Special tokens ─ IDs must match downstream model expectations.\n",
        "    pad_id=0,    pad_piece='<pad>',\n",
        "    unk_id=1,    unk_piece='<unk>',\n",
        "    bos_id=2,    bos_piece='<s>',\n",
        "    eos_id=3,    eos_piece='</s>',\n",
        "    character_coverage=0.9995, # keep almost every UTF‑8 char seen\n",
        "    model_type='bpe' # byte‑pair encoding variant\n",
        ")\n",
        "print(\"Done!\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4.  Runtime helpers\n",
        "# ---------------------------------------------------------------------------\n",
        "# Choose CPU vs GPU automatically.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the learned sub‑word model to tokenize on‑the‑fly.\n",
        "sp = spm.SentencePieceProcessor(model_file='data/bpe.model')\n",
        "PAD_ID = sp.pad_id()\n",
        "BOS_ID = sp.bos_id()\n",
        "EOS_ID = sp.eos_id()\n",
        "VOCAB = sp.get_piece_size()\n",
        "\n",
        "# ---------------------------\n",
        "# Encoding utility\n",
        "# -------------------------\n",
        "def encode(sentence):\n",
        "    \"\"\"Convert raw text to a list of integer token IDs.\n",
        "\n",
        "    • Truncate to `max_len‑1` to leave room for the explicit EOS.\n",
        "    • Append EOS so the decoder knows where to stop.\n",
        "    \"\"\"\n",
        "    ids = sp.encode(sentence, out_type=int)[:max_len-1]\n",
        "    return ids + [EOS_ID]\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5.  PyTorch Dataset wrapper\n",
        "# ---------------------------------------------------------------------------\n",
        "class TranslationDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Lazy wrapper that gives (src_sentence, tgt_sentence) tuples.\"\"\"\n",
        "    def __init__(self, split):\n",
        "        ds = load_dataset('IWSLT/iwslt2017', 'iwslt2017-en-fr', split=split)\n",
        "        self.src = [ex[\"translation\"][\"en\"] for ex in ds]\n",
        "        self.tgt = [ex[\"translation\"][\"fr\"] for ex in ds]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src[idx], self.tgt[idx]\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 6.  Batch collation: padding & tensor conversion\n",
        "# ---------------------------------------------------------------------------\n",
        "def collate(batch):\n",
        "    \"\"\"Custom collation to handle variable‑length sentences.\n",
        "\n",
        "    Steps\n",
        "    -----\n",
        "    1. Tokenize each sentence pair.\n",
        "    2. Compute max length inside the mini‑batch.\n",
        "    3. Right‑pad with <pad> so tensors become rectangular (B × T).\n",
        "    4. Return int64 tensors ready for `nn.Embedding` / `Transformer`.\n",
        "    \"\"\"\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "    src_ids = [encode(s) for s in src_batch]\n",
        "    tgt_ids = [encode(t) for t in tgt_batch]\n",
        "    src_max = max(len(x) for x in src_ids)\n",
        "    tgt_max = max(len(y) for y in tgt_ids)\n",
        "    src_pad = [x + [PAD_ID]*(src_max-len(x)) for x in src_ids]\n",
        "    tgt_pad = [y + [PAD_ID]*(tgt_max-len(y)) for y in tgt_ids]\n",
        "\n",
        "    return torch.tensor(src_pad), torch.tensor(tgt_pad)\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 7.  DataLoaders\n",
        "# ---------------------------------------------------------------------------\n",
        "train_loader = DataLoader(TranslationDataset('train[:50000]'), # subset for simpler experiments\n",
        "                          batch_size=lstm_batch_size,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=collate # our custom padding logic\n",
        "                          )\n",
        "\n",
        "val_dataset = TranslationDataset(split=\"validation[:1000]\")\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=lstm_batch_size,\n",
        "                        shuffle=False, # deterministic validation order\n",
        "                        collate_fn=collate)\n",
        "\n",
        "# `train_loader` and `val_loader` now stream padded token‑ID tensors\n",
        "# that can be fed straight into an LSTM and Transformer encoder‑decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtuVuWwW_jdV"
      },
      "source": [
        "### 4-1. LSTM baseline: Class definition\n",
        "\n",
        "Here, you need to use two modules:\n",
        "\n",
        "*   nn.Embedding\n",
        "  *   Turns a batch of integer token IDs into a batch of dense vectors (embedded vectors).\n",
        "  *   Input: ints in [0, vocab_size-1]\n",
        "  *   Output: lookup of a trainable table with shape [vocab, hidden]\n",
        "*   nn.LSTM\n",
        "  *   Learns to compress a sequence of those vectors into hidden states that capture context.\n",
        "  *   Input shape must be [B, T, H] if batch_first=True.\n",
        "  *   Returns every hidden state plus the last hidden & cell states separately.\n",
        "\n",
        "Please refer to the official documentation of PyTorch for detailed usage of each module.\n",
        "You should be careful about tensor shapes. I encourage you to print out tensor shapes the first time they run a batch:\n",
        "\n",
        "\n",
        "```\n",
        "print(x.shape, emb.shape, outs.shape, h.shape)   # sanity check\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kFu14pmr_vyh"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab, hidden):\n",
        "        super().__init__()\n",
        "        # ---- TODO students implement below ---- #\n",
        "        # Token ID → embedding vector conversion\n",
        "        self.embedding = nn.Embedding(vocab, hidden)\n",
        "        # LSTM layer with batch_first=True\n",
        "        self.lstm = nn.LSTM(input_size=hidden,\n",
        "                           hidden_size=hidden,\n",
        "                           num_layers=lstm_layers,\n",
        "                           dropout=lstm_dropout if lstm_layers > 1 else 0,\n",
        "                           batch_first=True)\n",
        "        self.dropout = nn.Dropout(lstm_dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)  # [B, T] -> [B, T, H]\n",
        "        emb = self.dropout(emb)\n",
        "        outputs, (h_n, c_n) = self.lstm(emb)\n",
        "        return outputs, (h_n, c_n)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab, hidden):\n",
        "        super().__init__()\n",
        "        # ---- TODO students implement below ---- #\n",
        "        self.embedding = nn.Embedding(vocab, hidden)\n",
        "        self.lstm = nn.LSTM(input_size=hidden,\n",
        "                           hidden_size=hidden,\n",
        "                           num_layers=lstm_layers,\n",
        "                           dropout=lstm_dropout if lstm_layers > 1 else 0,\n",
        "                           batch_first=True)\n",
        "        self.dropout = nn.Dropout(lstm_dropout)\n",
        "        # Output layer: maps hidden state to vocab-sized logits\n",
        "        self.fc = nn.Linear(hidden, vocab)\n",
        "\n",
        "    def forward(self, y, hidden):\n",
        "        emb = self.embedding(y)  # [B, T] -> [B, T, H]\n",
        "        emb = self.dropout(emb)\n",
        "        # Use encoder's hidden state as initial state\n",
        "        outputs, (h_n, c_n) = self.lstm(emb, hidden)\n",
        "        outputs = self.dropout(outputs)\n",
        "        logits = self.fc(outputs)  # [B, T, H] -> [B, T, V]\n",
        "        return logits, (h_n, c_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLSc1rZ8XtjX"
      },
      "source": [
        "### 4-2. LSTM baseline: Training loop\n",
        "\n",
        "**label_smoothed_nll_loss**\n",
        "\n",
        "In vanilla cross-entropy training the model is rewarded only when it places all probability mass on the single gold token.\n",
        "\n",
        "Side-effect: the network often becomes over-confident (p ≈ 1), which hurts generalization.\n",
        "\n",
        "Label smoothing fixes that by distributing a small portion ε of the probability mass over all classes.\n",
        "For a vocabulary of K tokens:\n",
        "\n",
        "```\n",
        "gold token prob      = 1 − ε\n",
        "every other token    = ε / K\n",
        "```\n",
        "We therefore minimize:\n",
        "\n",
        "```\n",
        "L = (1 − ε)⋅NLL + ε⋅UniformLoss\n",
        "```\n",
        "where\n",
        "* NLL = − log p(gold)\n",
        "* UniformLoss = − mean_j log p(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "03AnyYufWsSE"
      },
      "outputs": [],
      "source": [
        "def label_smoothed_nll_loss(lprobs, # raw logits  (B, T, V)  OR (any, V)\n",
        "                            target, # gold token IDs (B, T)\n",
        "                            epsilon=0.1, # smoothing factor ε\n",
        "                            ignore_index=PAD_ID # which ID means \"padding\"?\n",
        "                            ):\n",
        "    \"\"\"\n",
        "    Cross-entropy with label smoothing, padding aware.\n",
        "    Returns: scalar mean loss over non-pad tokens.\n",
        "    \"\"\"\n",
        "    n_class = lprobs.size(-1) # V = vocabulary size\n",
        "\n",
        "    # 1) Convert logits → log-probabilities for numerical stability\n",
        "    lprobs = F.log_softmax(lprobs, dim=-1)\n",
        "\n",
        "    # 2) Flatten batch/time dims so every token is an independent row\n",
        "    lprobs = lprobs.view(-1, n_class)  # (B·T, V)\n",
        "    target = target.contiguous().view(-1) # (B·T,)\n",
        "\n",
        "    # 3) Build mask for <pad> tokens and neutralize them\n",
        "    pad_mask = target.eq(ignore_index) # True where token == PAD_ID\n",
        "    target   = target.masked_fill(pad_mask, 0)  # dummy index 0 won’t be used\n",
        "\n",
        "    # 4) Negative-log-likelihood of the gold token\n",
        "    nll_loss     = F.nll_loss(lprobs, target,\n",
        "                              reduction='none' # keep per-token loss (B·T,)\n",
        "                              )\n",
        "\n",
        "    # 5) “Uniform” loss term: −Σ_j log p(j) / V\n",
        "    smooth_loss  = -lprobs.sum(dim=-1) / n_class\n",
        "\n",
        "    # 6) Interpolate:    (1-ε)·NLL  +  ε·Uniform\n",
        "    loss = (1 - epsilon) * nll_loss + epsilon * smooth_loss\n",
        "\n",
        "    # 7) Remove padding from both numerator & denominator\n",
        "    loss.masked_fill_(pad_mask, 0.0) # zero where pad\n",
        "    return loss.sum() / (~pad_mask).sum() # average over real tokens\n",
        "\n",
        "# Convenience alias so the usual training loop can read:\n",
        "criterion = label_smoothed_nll_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rtrRSbE2p4cT"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Model instantiation\n",
        "# ------------------------------\n",
        "# `VOCAB`, `lstm_hidden`, and `device` are defined earlier in the notebook.\n",
        "lstm_enc = Encoder(VOCAB, lstm_hidden).to(device)\n",
        "lstm_dec = Decoder(VOCAB, lstm_hidden).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7axG7LXXtI_",
        "outputId": "bd2f252b-47de-4526-da64-cc8fbb015ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[batch    1/391] loss=8.298\n",
            "[batch   50/391] loss=6.644\n",
            "[batch  100/391] loss=6.173\n",
            "[batch  150/391] loss=5.843\n",
            "[batch  200/391] loss=5.685\n",
            "[batch  250/391] loss=5.529\n",
            "[batch  300/391] loss=5.457\n",
            "[batch  350/391] loss=5.308\n",
            "Epoch 1: Train loss=5.876, Val loss=5.287, Val ppl=197.844\n",
            "[batch    1/391] loss=5.281\n",
            "[batch   50/391] loss=5.241\n",
            "[batch  100/391] loss=5.072\n",
            "[batch  150/391] loss=4.937\n",
            "[batch  200/391] loss=5.023\n",
            "[batch  250/391] loss=4.990\n",
            "[batch  300/391] loss=4.797\n",
            "[batch  350/391] loss=4.790\n",
            "Epoch 2: Train loss=5.006, Val loss=4.825, Val ppl=124.604\n",
            "[batch    1/391] loss=4.768\n",
            "[batch   50/391] loss=4.788\n",
            "[batch  100/391] loss=4.684\n",
            "[batch  150/391] loss=4.736\n",
            "[batch  200/391] loss=4.689\n",
            "[batch  250/391] loss=4.691\n",
            "[batch  300/391] loss=4.616\n",
            "[batch  350/391] loss=4.597\n",
            "Epoch 3: Train loss=4.703, Val loss=4.591, Val ppl=98.611\n",
            "[batch    1/391] loss=4.517\n",
            "[batch   50/391] loss=4.518\n",
            "[batch  100/391] loss=4.557\n",
            "[batch  150/391] loss=4.566\n",
            "[batch  200/391] loss=4.542\n",
            "[batch  250/391] loss=4.470\n",
            "[batch  300/391] loss=4.474\n",
            "[batch  350/391] loss=4.406\n",
            "Epoch 4: Train loss=4.520, Val loss=4.453, Val ppl=85.903\n",
            "[batch    1/391] loss=4.427\n",
            "[batch   50/391] loss=4.439\n",
            "[batch  100/391] loss=4.409\n",
            "[batch  150/391] loss=4.338\n",
            "[batch  200/391] loss=4.492\n",
            "[batch  250/391] loss=4.374\n",
            "[batch  300/391] loss=4.365\n",
            "[batch  350/391] loss=4.276\n",
            "Epoch 5: Train loss=4.386, Val loss=4.350, Val ppl=77.446\n",
            "[batch    1/391] loss=4.335\n",
            "[batch   50/391] loss=4.258\n",
            "[batch  100/391] loss=4.284\n",
            "[batch  150/391] loss=4.350\n",
            "[batch  200/391] loss=4.246\n",
            "[batch  250/391] loss=4.270\n",
            "[batch  300/391] loss=4.188\n",
            "[batch  350/391] loss=4.253\n",
            "Epoch 6: Train loss=4.257, Val loss=4.283, Val ppl=72.458\n",
            "[batch    1/391] loss=4.275\n",
            "[batch   50/391] loss=4.161\n",
            "[batch  100/391] loss=4.238\n",
            "[batch  150/391] loss=4.168\n",
            "[batch  200/391] loss=4.190\n",
            "[batch  250/391] loss=4.200\n",
            "[batch  300/391] loss=4.133\n",
            "[batch  350/391] loss=4.225\n",
            "Epoch 7: Train loss=4.191, Val loss=4.234, Val ppl=69.014\n",
            "[batch    1/391] loss=4.229\n",
            "[batch   50/391] loss=4.164\n",
            "[batch  100/391] loss=4.193\n",
            "[batch  150/391] loss=4.189\n",
            "[batch  200/391] loss=4.096\n",
            "[batch  250/391] loss=4.161\n",
            "[batch  300/391] loss=4.030\n",
            "[batch  350/391] loss=4.155\n",
            "Epoch 8: Train loss=4.137, Val loss=4.208, Val ppl=67.229\n",
            "[batch    1/391] loss=4.084\n",
            "[batch   50/391] loss=4.145\n",
            "[batch  100/391] loss=4.106\n",
            "[batch  150/391] loss=4.130\n",
            "[batch  200/391] loss=4.069\n",
            "[batch  250/391] loss=4.114\n",
            "[batch  300/391] loss=4.116\n",
            "[batch  350/391] loss=4.143\n",
            "Epoch 9: Train loss=4.090, Val loss=4.176, Val ppl=65.073\n",
            "[batch    1/391] loss=4.002\n",
            "[batch   50/391] loss=4.018\n",
            "[batch  100/391] loss=3.985\n",
            "[batch  150/391] loss=3.940\n",
            "[batch  200/391] loss=4.083\n",
            "[batch  250/391] loss=4.052\n",
            "[batch  300/391] loss=4.110\n",
            "[batch  350/391] loss=4.076\n",
            "Epoch 10: Train loss=4.047, Val loss=4.150, Val ppl=63.418\n",
            "[batch    1/391] loss=4.084\n",
            "[batch   50/391] loss=3.928\n",
            "[batch  100/391] loss=3.931\n",
            "[batch  150/391] loss=4.052\n",
            "[batch  200/391] loss=3.962\n",
            "[batch  250/391] loss=3.929\n",
            "[batch  300/391] loss=3.932\n",
            "[batch  350/391] loss=4.067\n",
            "Epoch 11: Train loss=3.990, Val loss=4.130, Val ppl=62.152\n",
            "[batch    1/391] loss=3.970\n",
            "[batch   50/391] loss=3.904\n",
            "[batch  100/391] loss=3.956\n",
            "[batch  150/391] loss=3.978\n",
            "[batch  200/391] loss=3.958\n",
            "[batch  250/391] loss=3.948\n",
            "[batch  300/391] loss=3.965\n",
            "[batch  350/391] loss=4.001\n",
            "Epoch 12: Train loss=3.962, Val loss=4.111, Val ppl=61.024\n",
            "[batch    1/391] loss=3.895\n",
            "[batch   50/391] loss=3.952\n",
            "[batch  100/391] loss=3.911\n",
            "[batch  150/391] loss=3.853\n",
            "[batch  200/391] loss=3.918\n",
            "[batch  250/391] loss=3.908\n",
            "[batch  300/391] loss=4.013\n",
            "[batch  350/391] loss=3.914\n",
            "Epoch 13: Train loss=3.940, Val loss=4.105, Val ppl=60.661\n",
            "[batch    1/391] loss=3.879\n",
            "[batch   50/391] loss=3.908\n",
            "[batch  100/391] loss=3.803\n",
            "[batch  150/391] loss=3.862\n",
            "[batch  200/391] loss=3.924\n",
            "[batch  250/391] loss=3.849\n",
            "[batch  300/391] loss=3.935\n",
            "[batch  350/391] loss=3.929\n",
            "Epoch 14: Train loss=3.917, Val loss=4.089, Val ppl=59.678\n",
            "[batch    1/391] loss=3.924\n",
            "[batch   50/391] loss=3.883\n",
            "[batch  100/391] loss=3.913\n",
            "[batch  150/391] loss=3.852\n",
            "[batch  200/391] loss=3.864\n",
            "[batch  250/391] loss=3.877\n",
            "[batch  300/391] loss=3.814\n",
            "[batch  350/391] loss=3.830\n",
            "Epoch 15: Train loss=3.896, Val loss=4.081, Val ppl=59.200\n",
            "[LSTM] Wall-clock training time :  81.06 min\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Training loop – Encoder–Decoder LSTM with label smoothing\n",
        "# ================================================================\n",
        "# This block shows one full experiment script: model instantiation, optimizer,\n",
        "# learning‑rate scheduler, epoch training, and validation evaluation.\n",
        "\n",
        "# ------------------------------\n",
        "# Optimizer\n",
        "# ------------------------------\n",
        "# Adam with the beta values (0.9, 0.98) and tiny eps for safety.\n",
        "optim = torch.optim.Adam(list(lstm_enc.parameters())+list(lstm_dec.parameters()),\n",
        "                          lr=1e-3, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# ------------------------------\n",
        "# LR scheduler: halve the LR every 5 epochs\n",
        "# ------------------------------\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.5)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# train_epoch() – one full sweep over the training DataLoader\n",
        "# ------------------------------------------------------------\n",
        "def train_epoch():\n",
        "    lstm_enc.train() # activate dropout & norm in train mode\n",
        "    lstm_dec.train()\n",
        "    total, n = 0, 0\n",
        "    for step, (src, tgt) in enumerate(train_loader, 1):\n",
        "        # Move mini‑batch to GPU/CPU device\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "        optim.zero_grad() # clear stale gradients\n",
        "\n",
        "        # Encoder forward pass\n",
        "        enc_out, hidden = lstm_enc(src) # hidden = (h_n, c_n)\n",
        "\n",
        "        # Decoder forward – feed gold tokens shifted right\n",
        "        logits, _ = lstm_dec(tgt[:, :-1], hidden)\n",
        "\n",
        "        # Flatten (B, T, V) → (B·T, V) and compute label‑smoothed CE\n",
        "        loss = criterion(logits.reshape(-1, VOCAB), tgt[:,1:].reshape(-1))\n",
        "\n",
        "        # Back‑prop\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to keep training stable (max‑norm = 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(lstm_enc.parameters(), 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(lstm_dec.parameters(), 1.0)\n",
        "\n",
        "        # Optimizer step (updates parameters)\n",
        "        optim.step()\n",
        "\n",
        "        # Accumulate loss for reporting\n",
        "        total += loss.item(); n += 1\n",
        "\n",
        "        # Report training loss every `lstm_log_interval` mini‑batches\n",
        "        if step % lstm_log_interval == 0 or step == 1:\n",
        "            print(f\"[batch {step:4}/{len(train_loader)}] \"\n",
        "            f\"loss={loss.item():.3f}\")\n",
        "\n",
        "    return total / n # epoch‑average loss\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# evaluate_loss() – no‑grad validation loop\n",
        "# ------------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model_enc, model_dec, loader, criterion, pad_id=PAD_ID):\n",
        "    model_enc.eval() # eval mode = disable dropout\n",
        "    model_dec.eval()\n",
        "    total, ntok = 0.0, 0 # token‑level aggregation\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        src_mask = (src != pad_id)\n",
        "\n",
        "        enc_out, hidden = model_enc(src)\n",
        "        logits, _ = model_dec(tgt[:, :-1], hidden)\n",
        "\n",
        "         # loss averaged per token (criterion already ignores PAD)\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, logits.size(-1)),\n",
        "            tgt[:, 1:].reshape(-1)\n",
        "        )\n",
        "\n",
        "        tokens = (tgt[:, 1:] != pad_id).sum().item() # non‑pad count\n",
        "        total += loss.item() * tokens # scale back to sum\n",
        "        ntok  += tokens\n",
        "\n",
        "    avg = total / ntok # mean NLL\n",
        "    ppl = math.exp(avg) # perplexity = e^(NLL)\n",
        "    return avg, ppl\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Main training loop across epochs\n",
        "# ------------------------------------------------------------\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "for epoch in range(1, lstm_epochs+1):\n",
        "    loss = train_epoch() # one pass over train set\n",
        "    val_loss, val_ppl = evaluate_loss(lstm_enc, lstm_dec, val_loader, criterion) # validation metrics\n",
        "    print(f\"Epoch {epoch}: Train loss={loss:.3f}, Val loss={val_loss:.3f}, Val ppl={val_ppl:.3f}\")\n",
        "\n",
        "    # Step the LR scheduler once per epoch\n",
        "    scheduler.step()\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"[LSTM] Wall-clock training time : {elapsed/60:6.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrv6_Xr6VmzM"
      },
      "source": [
        "### 5-1. Attention on LSTM: Class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IWC0sE6hVpQH"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Scaled dot‑product Attention (single‑head, batched)\n",
        "# ------------------------------------------------------------------\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden):\n",
        "        super().__init__()\n",
        "        # Linear layer projects decoder hidden → key/query space.\n",
        "        # Bias is set to False to keep the operation just a matrix mult.\n",
        "        self.W = nn.Linear(hidden, hidden, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_out):\n",
        "        \"\"\"Compute context vectors and attention weights.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "        decoder_hidden : [B, 1, H]  – current decoder time‑step hidden state\n",
        "        encoder_out    : [B, T_src, H] – all encoder outputs (keys/values)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        context        : [B, 1, H]\n",
        "        attn_weights   : [B, 1, T_src]\n",
        "        \"\"\"\n",
        "\n",
        "        # ---- TODO students implement below ---- #\n",
        "        # 1. Project decoder hidden through self.W  →  [B, 1, H]\n",
        "        # 2. Dot‑product with encoder_out^T via torch.bmm\n",
        "        #      scores = Q · K^T  →  [B, 1, T_src]\n",
        "        # 3. Softmax over T_src dimension to turn scores → probs\n",
        "        # 4. Weighted sum (context) = probs · V  via torch.bmm again\n",
        "        # --------------------------------------- #\n",
        "\n",
        "        # 1. Project decoder hidden through self.W\n",
        "        query = self.W(decoder_hidden)  # [B, 1, H]\n",
        "\n",
        "        # 2. Dot‑product with encoder_out^T via torch.bmm\n",
        "        # scores = Q · K^T\n",
        "        scores = torch.bmm(query, encoder_out.transpose(1, 2))  # [B, 1, T_src]\n",
        "\n",
        "        # 3. Softmax over T_src dimension to turn scores → probs\n",
        "        attn_weights = F.softmax(scores, dim=-1)  # [B, 1, T_src]\n",
        "\n",
        "        # 4. Weighted sum (context) = probs · V via torch.bmm\n",
        "        context = torch.bmm(attn_weights, encoder_out)  # [B, 1, H]\n",
        "\n",
        "        return context, attn_weights\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Attention‑augmented Decoder (one token at a time)\n",
        "# ------------------------------------------------------------------\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, vocab, hidden):\n",
        "        super().__init__()\n",
        "        # ---- TODO students implement below ---- #\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, hidden)\n",
        "        self.lstm = nn.LSTM(input_size=hidden,\n",
        "                            hidden_size=hidden,\n",
        "                            num_layers=lstm_layers,\n",
        "                            dropout=lstm_dropout if lstm_layers > 1 else 0,\n",
        "                            batch_first=True)\n",
        "        self.attention = Attention(hidden)\n",
        "        self.dropout = nn.Dropout(lstm_dropout)\n",
        "        self.out_dropout = nn.Dropout(lstm_dropout)\n",
        "        self.fc = nn.Linear(hidden, vocab)\n",
        "\n",
        "    def forward(self, y, hidden, enc_outputs):\n",
        "        \"\"\"Args\n",
        "        y           : [B, T_dec]   – gold tokens\n",
        "        hidden      : (h, c) tuple each [L, B, H]\n",
        "        enc_outputs : [B, T_src, H]\n",
        "        Returns\n",
        "        -------\n",
        "        logits      : [B, T_dec, vocab]\n",
        "        new_hidden  : (h_n, c_n)\n",
        "        \"\"\"\n",
        "        # ---- TODO students implement below ---- #\n",
        "        # 1. Embed y and apply dropout → emb  [B, T_dec, H]\n",
        "        # 2. Loop over each time‑step t because\n",
        "        #    we want to feed the previous decoder hidden to attention.\n",
        "        # 3. For every t, do attention and lstm operation\n",
        "        # 4. Concatenate outputs → [B, T_dec, H]\n",
        "        # 5. Apply out_dp then fc → logits\n",
        "        # 6. Return logits and last hidden state tuple.\n",
        "        # --------------------------------------- #\n",
        "\n",
        "        # 1. Embed y and apply dropout\n",
        "        emb = self.embedding(y)  # [B, T_dec, H]\n",
        "        emb = self.dropout(emb)\n",
        "\n",
        "        batch_size = emb.size(0)\n",
        "        seq_len = emb.size(1)\n",
        "        hidden_size = emb.size(2)\n",
        "\n",
        "        # Storage for collecting outputs\n",
        "        outputs = []\n",
        "\n",
        "        # 2. & 3. Process each timestep to use previous decoder state\n",
        "        for t in range(seq_len):\n",
        "            # Current timestep embedding\n",
        "            emb_t = emb[:, t:t+1, :]  # [B, 1, H]\n",
        "\n",
        "            # LSTM step\n",
        "            lstm_out, hidden = self.lstm(emb_t, hidden)  # [B, 1, H]\n",
        "\n",
        "            # Apply attention mechanism\n",
        "            context, _ = self.attention(lstm_out, enc_outputs)\n",
        "\n",
        "            # Combine context and LSTM output (simple addition)\n",
        "            combined = lstm_out + context  # [B, 1, H]\n",
        "\n",
        "            # Store result\n",
        "            outputs.append(combined)\n",
        "\n",
        "        # 4. Concatenate all outputs\n",
        "        outputs = torch.cat(outputs, dim=1)  # [B, T_dec, H]\n",
        "\n",
        "        # 5. Apply output dropout and projection\n",
        "        outputs = self.out_dropout(outputs)\n",
        "        logits = self.fc(outputs)  # [B, T_dec, vocab]\n",
        "\n",
        "        # 6. Return logits and final hidden state\n",
        "        return logits, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v7uLGGsXtSRz"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Model instantiation\n",
        "# ------------------------------\n",
        "attn_enc = Encoder(VOCAB, lstm_hidden).to(device)\n",
        "attn_dec = AttnDecoder(VOCAB, lstm_hidden).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT0xUCtKYKlU"
      },
      "source": [
        "### 5-2. Attention on LSTM: Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLgerpCMYMcj",
        "outputId": "6c9e7e51-d339-4d7d-fbca-36a68b9e1876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[batch    1/391] loss=8.296\n",
            "[batch   50/391] loss=5.908\n",
            "[batch  100/391] loss=5.381\n",
            "[batch  150/391] loss=4.963\n",
            "[batch  200/391] loss=4.780\n",
            "[batch  250/391] loss=4.584\n",
            "[batch  300/391] loss=4.522\n",
            "[batch  350/391] loss=4.387\n",
            "Epoch 1: Train loss=5.021, Val loss=4.330, Val ppl=75.951\n",
            "[batch    1/391] loss=4.247\n",
            "[batch   50/391] loss=4.206\n",
            "[batch  100/391] loss=4.169\n",
            "[batch  150/391] loss=4.082\n",
            "[batch  200/391] loss=4.128\n",
            "[batch  250/391] loss=4.078\n",
            "[batch  300/391] loss=3.922\n",
            "[batch  350/391] loss=3.980\n",
            "Epoch 2: Train loss=4.099, Val loss=3.904, Val ppl=49.598\n",
            "[batch    1/391] loss=3.866\n",
            "[batch   50/391] loss=3.847\n",
            "[batch  100/391] loss=3.742\n",
            "[batch  150/391] loss=3.867\n",
            "[batch  200/391] loss=3.811\n",
            "[batch  250/391] loss=3.824\n",
            "[batch  300/391] loss=3.779\n",
            "[batch  350/391] loss=3.765\n",
            "Epoch 3: Train loss=3.787, Val loss=3.702, Val ppl=40.522\n",
            "[batch    1/391] loss=3.623\n",
            "[batch   50/391] loss=3.579\n",
            "[batch  100/391] loss=3.584\n",
            "[batch  150/391] loss=3.670\n",
            "[batch  200/391] loss=3.492\n",
            "[batch  250/391] loss=3.569\n",
            "[batch  300/391] loss=3.520\n",
            "[batch  350/391] loss=3.578\n",
            "Epoch 4: Train loss=3.587, Val loss=3.552, Val ppl=34.883\n",
            "[batch    1/391] loss=3.502\n",
            "[batch   50/391] loss=3.445\n",
            "[batch  100/391] loss=3.447\n",
            "[batch  150/391] loss=3.477\n",
            "[batch  200/391] loss=3.453\n",
            "[batch  250/391] loss=3.448\n",
            "[batch  300/391] loss=3.402\n",
            "[batch  350/391] loss=3.474\n",
            "Epoch 5: Train loss=3.435, Val loss=3.449, Val ppl=31.471\n",
            "[batch    1/391] loss=3.339\n",
            "[batch   50/391] loss=3.377\n",
            "[batch  100/391] loss=3.331\n",
            "[batch  150/391] loss=3.280\n",
            "[batch  200/391] loss=3.208\n",
            "[batch  250/391] loss=3.347\n",
            "[batch  300/391] loss=3.397\n",
            "[batch  350/391] loss=3.185\n",
            "Epoch 6: Train loss=3.298, Val loss=3.335, Val ppl=28.066\n",
            "[batch    1/391] loss=3.099\n",
            "[batch   50/391] loss=3.151\n",
            "[batch  100/391] loss=3.143\n",
            "[batch  150/391] loss=3.152\n",
            "[batch  200/391] loss=3.135\n",
            "[batch  250/391] loss=3.216\n",
            "[batch  300/391] loss=3.090\n",
            "[batch  350/391] loss=3.170\n",
            "Epoch 7: Train loss=3.160, Val loss=3.245, Val ppl=25.649\n",
            "[batch    1/391] loss=2.935\n",
            "[batch   50/391] loss=3.009\n",
            "[batch  100/391] loss=2.950\n",
            "[batch  150/391] loss=3.099\n",
            "[batch  200/391] loss=3.098\n",
            "[batch  250/391] loss=3.002\n",
            "[batch  300/391] loss=2.978\n",
            "[batch  350/391] loss=2.965\n",
            "Epoch 8: Train loss=3.040, Val loss=3.166, Val ppl=23.720\n",
            "[batch    1/391] loss=2.972\n",
            "[batch   50/391] loss=2.908\n",
            "[batch  100/391] loss=2.959\n",
            "[batch  150/391] loss=2.945\n",
            "[batch  200/391] loss=2.909\n",
            "[batch  250/391] loss=2.923\n",
            "[batch  300/391] loss=2.880\n",
            "[batch  350/391] loss=2.923\n",
            "Epoch 9: Train loss=2.931, Val loss=3.086, Val ppl=21.884\n",
            "[batch    1/391] loss=2.862\n",
            "[batch   50/391] loss=2.827\n",
            "[batch  100/391] loss=2.784\n",
            "[batch  150/391] loss=2.898\n",
            "[batch  200/391] loss=2.821\n",
            "[batch  250/391] loss=2.909\n",
            "[batch  300/391] loss=2.851\n",
            "[batch  350/391] loss=2.889\n",
            "Epoch 10: Train loss=2.838, Val loss=3.023, Val ppl=20.549\n",
            "[batch    1/391] loss=2.755\n",
            "[batch   50/391] loss=2.794\n",
            "[batch  100/391] loss=2.789\n",
            "[batch  150/391] loss=2.670\n",
            "[batch  200/391] loss=2.731\n",
            "[batch  250/391] loss=2.766\n",
            "[batch  300/391] loss=2.775\n",
            "[batch  350/391] loss=2.884\n",
            "Epoch 11: Train loss=2.761, Val loss=2.978, Val ppl=19.650\n",
            "[batch    1/391] loss=2.669\n",
            "[batch   50/391] loss=2.740\n",
            "[batch  100/391] loss=2.664\n",
            "[batch  150/391] loss=2.783\n",
            "[batch  200/391] loss=2.703\n",
            "[batch  250/391] loss=2.709\n",
            "[batch  300/391] loss=2.800\n",
            "[batch  350/391] loss=2.704\n",
            "Epoch 12: Train loss=2.691, Val loss=2.934, Val ppl=18.806\n",
            "[batch    1/391] loss=2.560\n",
            "[batch   50/391] loss=2.515\n",
            "[batch  100/391] loss=2.635\n",
            "[batch  150/391] loss=2.700\n",
            "[batch  200/391] loss=2.736\n",
            "[batch  250/391] loss=2.612\n",
            "[batch  300/391] loss=2.708\n",
            "[batch  350/391] loss=2.645\n",
            "Epoch 13: Train loss=2.630, Val loss=2.908, Val ppl=18.319\n",
            "[batch    1/391] loss=2.510\n",
            "[batch   50/391] loss=2.479\n",
            "[batch  100/391] loss=2.564\n",
            "[batch  150/391] loss=2.555\n",
            "[batch  200/391] loss=2.543\n",
            "[batch  250/391] loss=2.592\n",
            "[batch  300/391] loss=2.699\n",
            "[batch  350/391] loss=2.630\n",
            "Epoch 14: Train loss=2.573, Val loss=2.868, Val ppl=17.599\n",
            "[batch    1/391] loss=2.390\n",
            "[batch   50/391] loss=2.492\n",
            "[batch  100/391] loss=2.521\n",
            "[batch  150/391] loss=2.602\n",
            "[batch  200/391] loss=2.475\n",
            "[batch  250/391] loss=2.583\n",
            "[batch  300/391] loss=2.437\n",
            "[batch  350/391] loss=2.566\n",
            "Epoch 15: Train loss=2.525, Val loss=2.840, Val ppl=17.115\n",
            "[LSTM with Attn] Wall-clock training time : 109.66 min\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Training loop – Attention‑based Sequence‑to‑Sequence Model\n",
        "# ================================================================\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "# Legend\n",
        "#  • `CrossEntropyLoss`      – vanilla CE (label smoothing was already demonstrated earlier)\n",
        "#  • `ReduceLROnPlateau`     – scheduler that halves LR when validation loss stagnates\n",
        "# -------------------------------------------------------------------------------------------------\n",
        "\n",
        "# ------------------------------\n",
        "# Optimizer setup\n",
        "# ------------------------------\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "\n",
        "optimizer = torch.optim.Adam(list(attn_enc.parameters()) + list(attn_dec.parameters()), lr=1e-3)\n",
        "\n",
        "# LR drops by ×0.5 if val‑loss fails to improve for one epoch.\n",
        "# `mode='min'` because we want the loss to go down.\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=1, verbose=True)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# train_epoch() – with attention\n",
        "# ------------------------------------------------------------\n",
        "def train_epoch():\n",
        "    attn_enc.train()\n",
        "    attn_dec.train()\n",
        "    total, ntok = 0, 0\n",
        "    for step, (src, tgt) in enumerate(train_loader, 1):\n",
        "       # ---------------- Mini‑batch prep ----------------\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ---------------- Forward pass -------------------\n",
        "        enc_out, hidden = attn_enc(src)\n",
        "        logits, _ = attn_dec(tgt[:, :-1], hidden, enc_out)\n",
        "\n",
        "        # CE expects (N, C) so reshape B×T×V → (B·T, V)\n",
        "        loss = criterion(logits.reshape(-1, VOCAB),\n",
        "                         tgt[:, 1:].reshape(-1))\n",
        "\n",
        "        # ---------------- Back‑prop ----------------------\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(attn_enc.parameters(), 1.0)\n",
        "        torch.nn.utils.clip_grad_norm_(attn_dec.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # ---------------- Stats --------------------------\n",
        "        tokens = (tgt[:,1:] != PAD_ID).sum().item()\n",
        "        total += loss.item() * tokens # accumulate sum over tokens\n",
        "        ntok  += tokens\n",
        "\n",
        "        if step % lstm_log_interval == 0 or step == 1:\n",
        "            print(f\"[batch {step:4}/{len(train_loader)}] \"\n",
        "            f\"loss={loss.item():.3f}\")\n",
        "\n",
        "    return total / ntok # token‑average loss per epoch\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Validation – evaluate_loss_attn (no‑grad)\n",
        "# ------------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate_loss_attn(model_enc, model_dec, loader, criterion, pad_id=PAD_ID):\n",
        "    model_enc.eval()\n",
        "    model_dec.eval()\n",
        "    total, ntok = 0.0, 0\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        src_mask = (src != pad_id)\n",
        "\n",
        "        enc_out, hidden = model_enc(src)\n",
        "        logits, _ = model_dec(tgt[:, :-1], hidden, enc_out)\n",
        "\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, logits.size(-1)),\n",
        "            tgt[:, 1:].reshape(-1)\n",
        "        )\n",
        "        tokens = (tgt[:, 1:] != pad_id).sum().item()\n",
        "        total += loss.item() * tokens\n",
        "        ntok  += tokens\n",
        "    avg = total / ntok\n",
        "    ppl = math.exp(avg)\n",
        "    return avg, ppl\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Epoch loop with plateau scheduler\n",
        "# ------------------------------------------------------------\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "for epoch in range(1, lstm_epochs+1):\n",
        "    loss = train_epoch() # one train pass\n",
        "    val_loss, val_ppl = evaluate_loss_attn(attn_enc, attn_dec, val_loader, criterion) # validation\n",
        "    print(f\"Epoch {epoch}: Train loss={loss:.3f}, Val loss={val_loss:.3f}, Val ppl={val_ppl:.3f}\")\n",
        "\n",
        "    # Reduce LR if no improvement; scheduler looks at val_loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"[LSTM with Attn] Wall-clock training time : {elapsed/60:6.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yxhz-g7e9cP"
      },
      "source": [
        "### 6-1. Transformer: Class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orZahp_tfB_W"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# PositionalEncoding – sinusoidal schedule explained\n",
        "# ------------------------------------------------------------------\n",
        "# Transformers have no recurrence or convolution, so they need an\n",
        "# explicit signal that tells them token #3 comes after token #2”.  This\n",
        "# positional encoding is added to the token embeddings before the\n",
        "# sequence enters the encoder/decoder.\n",
        "#\n",
        "# We use the classic sinusoidal embedding from the original Vaswani et\n",
        "# al. (2017) paper because:\n",
        "#   • it is fixed (no extra parameters to learn), and\n",
        "#   • any sequence length can be extrapolated thanks to sine/cosine\n",
        "#     periodicity.\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        \"\"\"Pre‑computes a [1, max_len, d_model] tensor of sinusoids.\n",
        "\n",
        "        Args\n",
        "        ----\n",
        "        d_model: dimensionality of embeddings fed into the Transformer.\n",
        "        max_len: longest sequence the model will ever see at inference.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # ------------------------------------------------------------------\n",
        "        # 1.  Build a lookup table `pe` where row i = position i (0‑indexed)\n",
        "        # ------------------------------------------------------------------\n",
        "        pe = torch.zeros(max_len, d_model) # [T, D]\n",
        "\n",
        "        # Positions: 0, 1, 2, …, T‑1  → shape [T, 1] so broadcasting works\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Denominator term 10000^{2k / d_model} implemented via exp/log.\n",
        "        # Only for even indices 0,2,4,…  (cosine will use the same term)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) # 0,2,4,…\n",
        "                            * -(math.log(10000.0) / d_model) # exponent factor\n",
        "                            ) # shape [D/2]\n",
        "\n",
        "        # Apply sin to even dims; cos to odd dims. Broadcasting does the\n",
        "        # heavy lifting so no explicit loops are needed.\n",
        "        pe[:, 0::2] = torch.sin(pos * div_term) # even indices  (0,2,…)\n",
        "        pe[:, 1::2] = torch.cos(pos * div_term) # odd  indices  (1,3,…)\n",
        "\n",
        "        # Transformer expects batch dimension first, so unsqueeze(0) → [1,T,D]\n",
        "        # `register_buffer` marks the tensor as part of the module’s state\n",
        "        # (saved with .state_dict()) but not a learnable parameter.\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Add positional encodings to input embeddings.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : [B, T, D] – token embeddings coming from `nn.Embedding`.\n",
        "        Returns\n",
        "        -------\n",
        "        out : [B, T, D] – embeddings plus positional signal.\n",
        "        \"\"\"\n",
        "        # Slice the first T positions (x.size(1)) and rely on broadcasting\n",
        "        # over the batch dimension: [1,T,D] + [B,T,D] → [B,T,D].\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# TransformerModel – step-by-step TODOs\n",
        "# ------------------------------------------------------------------\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab, d_model=256, nhead=4, nlayers=2):\n",
        "        super().__init__()\n",
        "        # -------- TODO students implement below -------- #\n",
        "        # 1. Token embedding with `padding_idx=PAD_ID` and embed_dim = d_model\n",
        "        # 2. PositionalEncoding instance (no learnable params)\n",
        "        # 3. Encoder–decoder stack:\n",
        "        #       enc_layer = nn.TransformerEncoderLayer(d_model, nhead,\n",
        "        #                       dim_feedforward=4*d_model, batch_first=True)\n",
        "        #       self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n",
        "        #   Repeat similarly for `nn.TransformerDecoder`.  Remember to use\n",
        "        #   batch_first=True so tensors stay [B, T, D].\n",
        "        # 4. Final linear layer maps D → vocab logits.\n",
        "        # ---------------------------------------------- #\n",
        "\n",
        "        # 1. Token embedding with `padding_idx=PAD_ID` and embed_dim = d_model\n",
        "        self.embed = nn.Embedding(vocab, d_model, padding_idx=PAD_ID)\n",
        "\n",
        "        # 2. PositionalEncoding instance (no learnable params)\n",
        "        self.pos = PositionalEncoding(d_model)\n",
        "\n",
        "        # 3. Encoder–decoder stack\n",
        "        # Encoder layers with batch_first=True\n",
        "        enc_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=4*d_model,\n",
        "            batch_first=True\n",
        "        )\n",
        "        # Stack encoder layers together\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, nlayers)\n",
        "\n",
        "        # Decoder layers with batch_first=True\n",
        "        dec_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=4*d_model,\n",
        "            batch_first=True\n",
        "        )\n",
        "        # Stack decoder layers together\n",
        "        self.decoder = nn.TransformerDecoder(dec_layer, nlayers)\n",
        "\n",
        "        # 4. Final linear layer maps D → vocab logits\n",
        "        self.fc = nn.Linear(d_model, vocab)\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt,\n",
        "                src_key_padding_mask=None,\n",
        "                tgt_key_padding_mask=None,\n",
        "                tgt_mask=None,\n",
        "                memory_key_padding_mask=None):\n",
        "\n",
        "        \"\"\"Forward pass with flexible masking.\n",
        "\n",
        "        * `src_key_padding_mask`    : [B, T_src]  – True where PAD in src\n",
        "        * `tgt_key_padding_mask`    : [B, T_tgt]  – True where PAD in tgt\n",
        "        * `tgt_mask` (causal)       : [T_tgt, T_tgt] – usually `generate_square_subsequent_mask(T_tgt)`\n",
        "        * `memory_key_padding_mask` : masks encoder output; defaults to src mask\n",
        "        \"\"\"\n",
        "        # -------- TODO students implement below -------- #\n",
        "        # 1. Embed + add/get positional encodings:\n",
        "        # 2. Encoder produces `memory` [B, T_src, D]\n",
        "        # 3. Decoder consumes (tgt, memory) and returns hidden states [B, T_tgt, D].\n",
        "        #    Pass all masking arguments to ensure padding & causality.\n",
        "        # 4. Project decoder outputs through `self.fc` → logits [B, T_tgt, vocab]\n",
        "        # 5. Return logits.\n",
        "        # ---------------------------------------------- #\n",
        "\n",
        "        # 1. Embed + add positional encodings\n",
        "        src_emb = self.pos(self.embed(src))  # [B, T_src, D]\n",
        "        tgt_emb = self.pos(self.embed(tgt))  # [B, T_tgt, D]\n",
        "\n",
        "        # If memory padding mask not provided, default to src padding mask\n",
        "        if memory_key_padding_mask is None:\n",
        "            memory_key_padding_mask = src_key_padding_mask\n",
        "\n",
        "        # 2. Encoder produces memory [B, T_src, D]\n",
        "        memory = self.encoder(\n",
        "            src_emb,\n",
        "            src_key_padding_mask=src_key_padding_mask\n",
        "        )\n",
        "\n",
        "        # 3. Decoder consumes (tgt, memory) and returns hidden states [B, T_tgt, D]\n",
        "        # Pass all masking arguments to ensure padding & causality\n",
        "        out = self.decoder(\n",
        "            tgt_emb,\n",
        "            memory,\n",
        "            tgt_mask=tgt_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask\n",
        "        )\n",
        "\n",
        "        # 4. Project decoder outputs through self.fc → logits [B, T_tgt, vocab]\n",
        "        logits = self.fc(out)\n",
        "\n",
        "        # 5. Return logits\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WubBW5t8frY4"
      },
      "source": [
        "### 6-2. Transformer: Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwYrMTw0u1d9"
      },
      "outputs": [],
      "source": [
        "# ------------------------------\n",
        "# Model instantiation\n",
        "# ------------------------------\n",
        "trans_model = TransformerModel(VOCAB, d_model, nhead, nlayers).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWP7El-fvRC",
        "outputId": "ec1eb238-0031-47b1-e5bf-1b0fa1f5e87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[batch    1/391] loss=6.777\n",
            "[batch   50/391] loss=6.067\n",
            "[batch  100/391] loss=5.447\n",
            "[batch  150/391] loss=5.300\n",
            "[batch  200/391] loss=5.038\n",
            "[batch  250/391] loss=4.786\n",
            "[batch  300/391] loss=4.808\n",
            "[batch  350/391] loss=4.646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train loss=5.215, Val loss=4.653, Val ppl=104.847\n",
            "[batch    1/391] loss=4.515\n",
            "[batch   50/391] loss=4.456\n",
            "[batch  100/391] loss=4.384\n",
            "[batch  150/391] loss=4.390\n",
            "[batch  200/391] loss=4.375\n",
            "[batch  250/391] loss=4.329\n",
            "[batch  300/391] loss=4.236\n",
            "[batch  350/391] loss=4.125\n",
            "Epoch 2: Train loss=4.325, Val loss=4.238, Val ppl=69.257\n",
            "[batch    1/391] loss=4.039\n",
            "[batch   50/391] loss=3.919\n",
            "[batch  100/391] loss=3.894\n",
            "[batch  150/391] loss=3.871\n",
            "[batch  200/391] loss=3.800\n",
            "[batch  250/391] loss=3.679\n",
            "[batch  300/391] loss=3.704\n",
            "[batch  350/391] loss=3.681\n",
            "Epoch 3: Train loss=3.792, Val loss=3.821, Val ppl=45.671\n",
            "[batch    1/391] loss=3.380\n",
            "[batch   50/391] loss=3.461\n",
            "[batch  100/391] loss=3.436\n",
            "[batch  150/391] loss=3.346\n",
            "[batch  200/391] loss=3.324\n",
            "[batch  250/391] loss=3.390\n",
            "[batch  300/391] loss=3.299\n",
            "[batch  350/391] loss=3.222\n",
            "Epoch 4: Train loss=3.332, Val loss=3.557, Val ppl=35.051\n",
            "[batch    1/391] loss=3.000\n",
            "[batch   50/391] loss=2.945\n",
            "[batch  100/391] loss=3.112\n",
            "[batch  150/391] loss=3.007\n",
            "[batch  200/391] loss=2.953\n",
            "[batch  250/391] loss=2.980\n",
            "[batch  300/391] loss=3.056\n",
            "[batch  350/391] loss=3.066\n",
            "Epoch 5: Train loss=3.015, Val loss=3.365, Val ppl=28.934\n",
            "[batch    1/391] loss=2.790\n",
            "[batch   50/391] loss=2.853\n",
            "[batch  100/391] loss=2.868\n",
            "[batch  150/391] loss=2.778\n",
            "[batch  200/391] loss=2.771\n",
            "[batch  250/391] loss=2.798\n",
            "[batch  300/391] loss=2.864\n",
            "[batch  350/391] loss=2.776\n",
            "Epoch 6: Train loss=2.799, Val loss=3.275, Val ppl=26.448\n",
            "[batch    1/391] loss=2.637\n",
            "[batch   50/391] loss=2.563\n",
            "[batch  100/391] loss=2.658\n",
            "[batch  150/391] loss=2.686\n",
            "[batch  200/391] loss=2.640\n",
            "[batch  250/391] loss=2.639\n",
            "[batch  300/391] loss=2.668\n",
            "[batch  350/391] loss=2.759\n",
            "Epoch 7: Train loss=2.642, Val loss=3.232, Val ppl=25.327\n",
            "[batch    1/391] loss=2.400\n",
            "[batch   50/391] loss=2.481\n",
            "[batch  100/391] loss=2.555\n",
            "[batch  150/391] loss=2.551\n",
            "[batch  200/391] loss=2.505\n",
            "[batch  250/391] loss=2.534\n",
            "[batch  300/391] loss=2.516\n",
            "[batch  350/391] loss=2.585\n",
            "Epoch 8: Train loss=2.520, Val loss=3.203, Val ppl=24.614\n",
            "[batch    1/391] loss=2.362\n",
            "[batch   50/391] loss=2.393\n",
            "[batch  100/391] loss=2.451\n",
            "[batch  150/391] loss=2.370\n",
            "[batch  200/391] loss=2.394\n",
            "[batch  250/391] loss=2.477\n",
            "[batch  300/391] loss=2.399\n",
            "[batch  350/391] loss=2.420\n",
            "Epoch 9: Train loss=2.419, Val loss=3.203, Val ppl=24.599\n",
            "[batch    1/391] loss=2.266\n",
            "[batch   50/391] loss=2.308\n",
            "[batch  100/391] loss=2.253\n",
            "[batch  150/391] loss=2.296\n",
            "[batch  200/391] loss=2.378\n",
            "[batch  250/391] loss=2.371\n",
            "[batch  300/391] loss=2.339\n",
            "[batch  350/391] loss=2.321\n",
            "Epoch 10: Train loss=2.334, Val loss=3.202, Val ppl=24.587\n",
            "[batch    1/391] loss=2.155\n",
            "[batch   50/391] loss=2.151\n",
            "[batch  100/391] loss=2.267\n",
            "[batch  150/391] loss=2.239\n",
            "[batch  200/391] loss=2.268\n",
            "[batch  250/391] loss=2.290\n",
            "[batch  300/391] loss=2.374\n",
            "[batch  350/391] loss=2.266\n",
            "Epoch 11: Train loss=2.261, Val loss=3.213, Val ppl=24.846\n",
            "[batch    1/391] loss=2.069\n",
            "[batch   50/391] loss=2.100\n",
            "[batch  100/391] loss=2.211\n",
            "[batch  150/391] loss=2.152\n",
            "[batch  200/391] loss=2.207\n",
            "[batch  250/391] loss=2.166\n",
            "[batch  300/391] loss=2.262\n",
            "[batch  350/391] loss=2.217\n",
            "Epoch 12: Train loss=2.196, Val loss=3.223, Val ppl=25.107\n",
            "[batch    1/391] loss=2.062\n",
            "[batch   50/391] loss=2.018\n",
            "[batch  100/391] loss=2.123\n",
            "[batch  150/391] loss=2.124\n",
            "[batch  200/391] loss=2.159\n",
            "[batch  250/391] loss=2.138\n",
            "[batch  300/391] loss=2.183\n",
            "[batch  350/391] loss=2.182\n",
            "Epoch 13: Train loss=2.140, Val loss=3.248, Val ppl=25.730\n",
            "[batch    1/391] loss=2.026\n",
            "[batch   50/391] loss=2.031\n",
            "[batch  100/391] loss=2.093\n",
            "[batch  150/391] loss=2.118\n",
            "[batch  200/391] loss=2.089\n",
            "[batch  250/391] loss=2.137\n",
            "[batch  300/391] loss=2.117\n",
            "[batch  350/391] loss=2.177\n",
            "Epoch 14: Train loss=2.089, Val loss=3.245, Val ppl=25.664\n",
            "[batch    1/391] loss=1.951\n",
            "[batch   50/391] loss=1.944\n",
            "[batch  100/391] loss=1.981\n",
            "[batch  150/391] loss=2.037\n",
            "[batch  200/391] loss=2.075\n",
            "[batch  250/391] loss=2.120\n",
            "[batch  300/391] loss=2.058\n",
            "[batch  350/391] loss=2.088\n",
            "Epoch 15: Train loss=2.043, Val loss=3.266, Val ppl=26.206\n",
            "[Transformer] Wall-clock training time :  47.83 min\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Training loop – Encoder–Decoder Transformer with AdamW\n",
        "# ================================================================\n",
        "# This block is the Transformer counterpart to the LSTM and Attn-LSTM\n",
        "# loops shown earlier.  It introduces two new ingredients:\n",
        "#   • `torch.optim.AdamW`  – Adam variant with decoupled weight decay.\n",
        "#   • A causal mask (`gen_square_sub_mask`) so the decoder can’t peek\n",
        "#     at future tokens during training.\n",
        "\n",
        "# ------------------------------\n",
        "# Optimizer\n",
        "# ------------------------------\n",
        "\n",
        "# AdamW is preferred for Transformers; betas match the original paper.\n",
        "optimizer = torch.optim.AdamW(trans_model.parameters(), lr=trans_base_lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# ------------------------------\n",
        "# Utility: generate causal decoder mask\n",
        "# ------------------------------\n",
        "def gen_square_sub_mask(sz, device):\n",
        "    \"\"\"Upper‑triangular matrix with −inf above the main diagonal.\n",
        "\n",
        "    When added to query–key scores inside `nn.MultiheadAttention`, these\n",
        "    −inf values turn into 0 after softmax → effectively masking future\n",
        "    positions.\n",
        "    \"\"\"\n",
        "    return torch.triu(torch.full((sz, sz), float('-inf'),\n",
        "                      device=device),\n",
        "                      diagonal=1) # start one step above main diagonal\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# train_epoch() for Transformer\n",
        "# ------------------------------------------------------------\n",
        "def train_epoch():\n",
        "    trans_model.train()\n",
        "    total_loss, total_tok = 0.0, 0\n",
        "\n",
        "    for step, (src, tgt) in enumerate(train_loader, 1):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Padding masks (True where PAD)\n",
        "        src_key_padding = src.eq(PAD_ID) # [B, T_src]\n",
        "        tgt_input = tgt[:, :-1] # decoder inputs (shifted)\n",
        "        tgt_key_padding = tgt_input.eq(PAD_ID) # [B, T_tgt]\n",
        "\n",
        "        # Causal mask – ensures tokens attend only to earlier positions.\n",
        "        tgt_mask = gen_square_sub_mask(tgt_input.size(1), device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = trans_model(src, tgt_input,\n",
        "                       src_key_padding_mask=src_key_padding,\n",
        "                       tgt_key_padding_mask=tgt_key_padding,\n",
        "                       tgt_mask=tgt_mask) # [B, T_tgt, V]\n",
        "\n",
        "        # Label‑smoothed loss (defined earlier) expects log‑probs\n",
        "        loss = label_smoothed_nll_loss(F.log_softmax(logits, -1), # convert to log‑p\n",
        "                                       tgt[:, 1:]) # decoder targets (shifted)\n",
        "\n",
        "        # Back‑prop and optimization\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(trans_model.parameters(), 1.0)\n",
        "        optimizer.step();\n",
        "\n",
        "        # Aggregate stats\n",
        "        ntok = tgt[:, 1:].ne(PAD_ID).sum().item()\n",
        "        total_loss += loss.item() * ntok\n",
        "        total_tok  += ntok\n",
        "\n",
        "        if step % trans_log_interval == 0 or step == 1:\n",
        "            print(f\"[batch {step:4}/{len(train_loader)}] \"\n",
        "            f\"loss={loss.item():.3f}\")\n",
        "\n",
        "    return total_loss / total_tok # token‑average loss over epoch\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Validation loop (no‑grad)\n",
        "# ------------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate_loss_transformer(model, loader, criterion, pad_id=PAD_ID):\n",
        "    model.eval()\n",
        "    total, ntok = 0.0, 0\n",
        "\n",
        "    for src, tgt in loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        src_key_padding = src.eq(pad_id)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_key_padding = tgt_input.eq(pad_id)\n",
        "        tgt_mask = gen_square_sub_mask(tgt_input.size(1), device)\n",
        "\n",
        "        logits = model(src, tgt_input,\n",
        "                     src_key_padding_mask=src_key_padding,\n",
        "                     tgt_key_padding_mask=tgt_key_padding,\n",
        "                     tgt_mask=tgt_mask)\n",
        "\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)),\n",
        "                       tgt[:, 1:].reshape(-1))\n",
        "\n",
        "        tokens = (tgt[:, 1:] != pad_id).sum().item()\n",
        "        total += loss.item() * tokens\n",
        "        ntok += tokens\n",
        "\n",
        "    avg = total / ntok\n",
        "    ppl = math.exp(avg)\n",
        "    return avg, ppl\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Epoch loop\n",
        "# ------------------------------------------------------------\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "for epoch in range(1, trans_epochs + 1):\n",
        "    loss = train_epoch()\n",
        "    val_loss, val_ppl = evaluate_loss_transformer(trans_model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch}: Train loss={loss:.3f}, Val loss={val_loss:.3f}, Val ppl={val_ppl:.3f}\")\n",
        "\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"[Transformer] Wall-clock training time : {elapsed/60:6.2f} min\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3rplS1ujao0"
      },
      "source": [
        "### 7. Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CRANP8Iajkge"
      },
      "outputs": [],
      "source": [
        "# Example sentence\n",
        "en_sentence = \"A person is wearing a hat.\"\n",
        "\n",
        "# You may not get good translation results since we've trained the models\n",
        "# with small capacity and datasets.\n",
        "# However, you can see that the more advanced model can capture some contexts.\n",
        "# You are totally allowed to change the sentence for different tries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5mJ5XN5j67M"
      },
      "source": [
        "### 7-1. Tranlation example: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grJiIpCkkASF",
        "outputId": "4ae0d248-8eda-4fbb-fd91-5947fb6d774d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Translation Result:\n",
            "▶︎ A person is wearing a hat.\n",
            "   → itablement que c'est un peu\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Greedy inference – `translate_lstm`\n",
        "# ================================================================\n",
        "# At training time we ran teacher forcing (feeding gold tokens).\n",
        "# During inference we must generate one token at a time and feed each\n",
        "# prediction back into the decoder. The helper below performs greedy\n",
        "# decoding—always picking the highest‐probability token at every step.\n",
        "\n",
        "def translate_lstm(src_sentence):\n",
        "    \"\"\"Translate English→French using the trained LSTM seq2seq model.\n",
        "\n",
        "    Steps\n",
        "    -----\n",
        "    1.  Switch encoder/decoder to `eval()` so dropout is disabled.\n",
        "    2.  `encode()` the raw source sentence → list[int].  Wrap in a\n",
        "        batch‐dim `[1, T]` and move to device.\n",
        "    3.  Run the encoder once to get all hidden states + final (h, c).\n",
        "    4.  Initialize the decoder input with just `<s>` (BOS).\n",
        "    5.  Loop up to `max_len` – each iteration:\n",
        "        a. Feed the last generated token to decoder.\n",
        "        b. Take `argmax` over vocabulary to get the next token ID.\n",
        "        c. Append the new token to `ys`.\n",
        "        d. If the token is `</s>` (EOS) → break early.\n",
        "    6.  Remove BOS/EOS, convert IDs back to text with `sp.decode()`.\n",
        "    \"\"\"\n",
        "    lstm_enc.eval() # 1. evaluation mode\n",
        "    lstm_dec.eval()\n",
        "\n",
        "    src_ids = torch.tensor([encode(src_sentence)], device=device) # 2.\n",
        "\n",
        "    enc_out, hidden = lstm_enc(src_ids) # 3. encoder forward\n",
        "\n",
        "    ys = torch.tensor([[BOS_ID]], device=device) # 4. start symbol\n",
        "\n",
        "    for _ in range(max_len): # 5. generate token by token\n",
        "          logits, hidden = lstm_dec(ys[:, -1:], hidden) # a. last token only\n",
        "          next_id = logits[:, -1, :].argmax(-1) # b. greedy pick\n",
        "          ys = torch.cat([ys, next_id.unsqueeze(1)], dim=1) # c. append\n",
        "          if next_id.item() == EOS_ID: # d. stop condition\n",
        "              break\n",
        "\n",
        "    tgt_tokens = ys[0, 1:-1].tolist() # strip BOS & EOS\n",
        "    return sp.decode(tgt_tokens) # 6. detokenize\n",
        "\n",
        "print(\"LSTM Translation Result:\")\n",
        "print(f\"▶︎ {en_sentence}\")\n",
        "print(\"   →\", translate_lstm(en_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFpsq3wrlz7c"
      },
      "source": [
        "### 7-2. Tranlation example: LSTM with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWlEvDB8l3fM",
        "outputId": "e70034ca-cdb9-43e1-d074-b9f74b5862d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM with Attention Translation Result:\n",
            "▶︎ A person is wearing a hat.\n",
            "   → personne ne s'est mis un pied.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Greedy inference – `translate_attn`\n",
        "# ================================================================\n",
        "\n",
        "def translate_attn(src_sentence):\n",
        "    attn_enc.eval()\n",
        "    attn_dec.eval()\n",
        "\n",
        "    src_ids = torch.tensor([encode(src_sentence)], device=device)\n",
        "\n",
        "    enc_out, hidden = attn_enc(src_ids)\n",
        "\n",
        "    ys = torch.tensor([[BOS_ID]], device=device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "          logits, hidden = attn_dec(ys[:, -1:], hidden, enc_out)\n",
        "          next_id = logits[:, -1, :].argmax(-1)\n",
        "          ys = torch.cat([ys, next_id.unsqueeze(1)], dim=1)\n",
        "          if next_id.item() == EOS_ID:\n",
        "              break\n",
        "\n",
        "    tgt_tokens = ys[0, 1:-1].tolist()\n",
        "    return sp.decode(tgt_tokens)\n",
        "\n",
        "print(\"LSTM with Attention Translation Result:\")\n",
        "print(f\"▶︎ {en_sentence}\")\n",
        "print(\"   →\", translate_attn(en_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXw26GqImFrP"
      },
      "source": [
        "### 7-3. Tranlation example: Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p2owXkTmIUw",
        "outputId": "92186353-cd5f-4a28-841b-cdecbcbbcb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer Translation Result:\n",
            "▶︎ A person is wearing a hat.\n",
            "   → mons un chapitre.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 16.  Greedy inference – `translate_trans` for Transformer\n",
        "# ================================================================\n",
        "# This routine mirrors `translate_lstm` but uses the Transformer model.\n",
        "# Main differences:\n",
        "#   • We precompute the memory (encoder output) once.\n",
        "#   • Every decoding step requires a causal mask for self‑attention.\n",
        "#   • Padding masks must be passed to both decoder and encoder–decoder\n",
        "#     attention so PAD tokens don't influence the context.\n",
        "\n",
        "def translate_trans(src_sent):\n",
        "    \"\"\"Translate a single sentence with the trained Transformer.\"\"\"\n",
        "    trans_model.eval() # disable dropout\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # 1.  Encode the source sentence ONCE\n",
        "    # ------------------------------------------------------------\n",
        "    src_ids = torch.tensor([encode(src_sent)], device=device) # [1, T_src]\n",
        "    src_key = src_ids.eq(PAD_ID) # [1, T_src] bool\n",
        "\n",
        "    # token embed + positional encodings\n",
        "    memory = trans_model.embed(src_ids) # [1, T_src, D]\n",
        "    memory = trans_model.pos(memory) # add sin/cos positions\n",
        "\n",
        "    # run through the encoder stack → `memory`\n",
        "    memory = trans_model.encoder(memory, src_key_padding_mask=src_key)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # 2.  Autoregressive decoder loop (greedy)\n",
        "    # ------------------------------------------------------------\n",
        "    ys = torch.tensor([[BOS_ID]], device=device)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Causal mask grows with sequence length\n",
        "        tgt_mask = gen_square_sub_mask(ys.size(1), device) # [T_tgt, T_tgt]\n",
        "        tgt_key  = ys.eq(PAD_ID) # padding mask\n",
        "\n",
        "         # Embed + positional\n",
        "        out = trans_model.embed(ys)\n",
        "        out = trans_model.pos(out)\n",
        "\n",
        "        # Decoder: queries = out, keys/values from memory\n",
        "        out = trans_model.decoder(out, memory,\n",
        "                                  tgt_mask=tgt_mask,\n",
        "                                  tgt_key_padding_mask=tgt_key,\n",
        "                                  memory_key_padding_mask=src_key\n",
        "                                  ) # [1, T_tgt, D]\n",
        "\n",
        "        # Project newest time‑step to vocabulary and pick argmax\n",
        "        next_tok = trans_model.fc(out[:, -1, :]).argmax(-1) # [1]\n",
        "\n",
        "        ys = torch.cat([ys, next_tok.unsqueeze(1)], dim=1) # append\n",
        "        if next_tok.item() == EOS_ID: break # stop if </s> generated\n",
        "\n",
        "    # Strip BOS/EOS and detokenize\n",
        "    return sp.decode(ys[0, 1:-1].tolist())\n",
        "\n",
        "print(\"Transformer Translation Result:\")\n",
        "print(f\"▶︎ {en_sentence}\")\n",
        "print(\"   →\", translate_trans(en_sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ0h2_H1M32Z"
      },
      "source": [
        "### 8. Model summary\n",
        "Shows number of parameters, multiply-adds (MACs) of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPPV_CgVpJ4v",
        "outputId": "56b87f7a-10fc-4620-bad7-51b0b266e715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Param #                   Mult-Adds\n",
            "==========================================================================================\n",
            "Encoder                                  --                        --\n",
            "├─Embedding: 1-1                         4,096,000                 4,096,000\n",
            "├─Dropout: 1-2                           --                        --\n",
            "├─LSTM: 1-3                              25,190,400                755,712,000\n",
            "==========================================================================================\n",
            "Total params: 29,286,400\n",
            "Trainable params: 29,286,400\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 759.81\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.49\n",
            "Params size (MB): 117.15\n",
            "Estimated Total Size (MB): 117.64\n",
            "==========================================================================================\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Param #                   Mult-Adds\n",
            "==========================================================================================\n",
            "Decoder                                  --                        --\n",
            "├─Embedding: 1-1                         4,096,000                 4,096,000\n",
            "├─Dropout: 1-2                           --                        --\n",
            "├─LSTM: 1-3                              25,190,400                730,521,600\n",
            "├─Dropout: 1-4                           --                        --\n",
            "├─Linear: 1-5                            4,100,000                 4,100,000\n",
            "==========================================================================================\n",
            "Total params: 33,386,400\n",
            "Trainable params: 33,386,400\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 738.72\n",
            "==========================================================================================\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 1.40\n",
            "Params size (MB): 133.55\n",
            "Estimated Total Size (MB): 134.97\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary of LSTM ENC\n",
        "print(summary(lstm_enc, input_size=(1, 30), dtypes=[torch.long], col_names=(\"num_params\", \"mult_adds\")))\n",
        "\n",
        "# Summary of LSTM DEC\n",
        "y = torch.randint(0, VOCAB, (1, 29), dtype=torch.long).to(device)\n",
        "h = torch.randn(lstm_layers, 1, lstm_hidden).to(device)\n",
        "c = torch.randn(lstm_layers, 1, lstm_hidden).to(device)\n",
        "hidden = (h, c)\n",
        "print(summary(lstm_dec, input_data=(y, hidden), dtypes=[torch.long], col_names=(\"num_params\", \"mult_adds\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6QcdtBwspyh",
        "outputId": "7d5e4a7c-31f0-48bc-d0e1-fad064b0c8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Param #                   Mult-Adds\n",
            "==========================================================================================\n",
            "Encoder                                  --                        --\n",
            "├─Embedding: 1-1                         4,096,000                 4,096,000\n",
            "├─Dropout: 1-2                           --                        --\n",
            "├─LSTM: 1-3                              25,190,400                755,712,000\n",
            "==========================================================================================\n",
            "Total params: 29,286,400\n",
            "Trainable params: 29,286,400\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 759.81\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.49\n",
            "Params size (MB): 117.15\n",
            "Estimated Total Size (MB): 117.64\n",
            "==========================================================================================\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Param #                   Mult-Adds\n",
            "==========================================================================================\n",
            "AttnDecoder                              --                        --\n",
            "├─Embedding: 1-1                         4,096,000                 4,096,000\n",
            "├─Dropout: 1-2                           --                        --\n",
            "├─LSTM: 1-3                              25,190,400                25,190,400\n",
            "├─Attention: 1-4                         --                        --\n",
            "│    └─Linear: 2-1                       1,048,576                 1,048,576\n",
            "├─LSTM: 1-5                              (recursive)               25,190,400\n",
            "├─Attention: 1-6                         (recursive)               --\n",
            "│    └─Linear: 2-2                       (recursive)               1,048,576\n",
            "├─LSTM: 1-7                              (recursive)               25,190,400\n",
            "├─Attention: 1-8                         (recursive)               --\n",
            "│    └─Linear: 2-3                       (recursive)               1,048,576\n",
            "├─LSTM: 1-9                              (recursive)               25,190,400\n",
            "├─Attention: 1-10                        (recursive)               --\n",
            "│    └─Linear: 2-4                       (recursive)               1,048,576\n",
            "├─LSTM: 1-11                             (recursive)               25,190,400\n",
            "├─Attention: 1-12                        (recursive)               --\n",
            "│    └─Linear: 2-5                       (recursive)               1,048,576\n",
            "├─LSTM: 1-13                             (recursive)               25,190,400\n",
            "├─Attention: 1-14                        (recursive)               --\n",
            "│    └─Linear: 2-6                       (recursive)               1,048,576\n",
            "├─LSTM: 1-15                             (recursive)               25,190,400\n",
            "├─Attention: 1-16                        (recursive)               --\n",
            "│    └─Linear: 2-7                       (recursive)               1,048,576\n",
            "├─LSTM: 1-17                             (recursive)               25,190,400\n",
            "├─Attention: 1-18                        (recursive)               --\n",
            "│    └─Linear: 2-8                       (recursive)               1,048,576\n",
            "├─LSTM: 1-19                             (recursive)               25,190,400\n",
            "├─Attention: 1-20                        (recursive)               --\n",
            "│    └─Linear: 2-9                       (recursive)               1,048,576\n",
            "├─LSTM: 1-21                             (recursive)               25,190,400\n",
            "├─Attention: 1-22                        (recursive)               --\n",
            "│    └─Linear: 2-10                      (recursive)               1,048,576\n",
            "├─LSTM: 1-23                             (recursive)               25,190,400\n",
            "├─Attention: 1-24                        (recursive)               --\n",
            "│    └─Linear: 2-11                      (recursive)               1,048,576\n",
            "├─LSTM: 1-25                             (recursive)               25,190,400\n",
            "├─Attention: 1-26                        (recursive)               --\n",
            "│    └─Linear: 2-12                      (recursive)               1,048,576\n",
            "├─LSTM: 1-27                             (recursive)               25,190,400\n",
            "├─Attention: 1-28                        (recursive)               --\n",
            "│    └─Linear: 2-13                      (recursive)               1,048,576\n",
            "├─LSTM: 1-29                             (recursive)               25,190,400\n",
            "├─Attention: 1-30                        (recursive)               --\n",
            "│    └─Linear: 2-14                      (recursive)               1,048,576\n",
            "├─LSTM: 1-31                             (recursive)               25,190,400\n",
            "├─Attention: 1-32                        (recursive)               --\n",
            "│    └─Linear: 2-15                      (recursive)               1,048,576\n",
            "├─LSTM: 1-33                             (recursive)               25,190,400\n",
            "├─Attention: 1-34                        (recursive)               --\n",
            "│    └─Linear: 2-16                      (recursive)               1,048,576\n",
            "├─LSTM: 1-35                             (recursive)               25,190,400\n",
            "├─Attention: 1-36                        (recursive)               --\n",
            "│    └─Linear: 2-17                      (recursive)               1,048,576\n",
            "├─LSTM: 1-37                             (recursive)               25,190,400\n",
            "├─Attention: 1-38                        (recursive)               --\n",
            "│    └─Linear: 2-18                      (recursive)               1,048,576\n",
            "├─LSTM: 1-39                             (recursive)               25,190,400\n",
            "├─Attention: 1-40                        (recursive)               --\n",
            "│    └─Linear: 2-19                      (recursive)               1,048,576\n",
            "├─LSTM: 1-41                             (recursive)               25,190,400\n",
            "├─Attention: 1-42                        (recursive)               --\n",
            "│    └─Linear: 2-20                      (recursive)               1,048,576\n",
            "├─LSTM: 1-43                             (recursive)               25,190,400\n",
            "├─Attention: 1-44                        (recursive)               --\n",
            "│    └─Linear: 2-21                      (recursive)               1,048,576\n",
            "├─LSTM: 1-45                             (recursive)               25,190,400\n",
            "├─Attention: 1-46                        (recursive)               --\n",
            "│    └─Linear: 2-22                      (recursive)               1,048,576\n",
            "├─LSTM: 1-47                             (recursive)               25,190,400\n",
            "├─Attention: 1-48                        (recursive)               --\n",
            "│    └─Linear: 2-23                      (recursive)               1,048,576\n",
            "├─LSTM: 1-49                             (recursive)               25,190,400\n",
            "├─Attention: 1-50                        (recursive)               --\n",
            "│    └─Linear: 2-24                      (recursive)               1,048,576\n",
            "├─LSTM: 1-51                             (recursive)               25,190,400\n",
            "├─Attention: 1-52                        (recursive)               --\n",
            "│    └─Linear: 2-25                      (recursive)               1,048,576\n",
            "├─LSTM: 1-53                             (recursive)               25,190,400\n",
            "├─Attention: 1-54                        (recursive)               --\n",
            "│    └─Linear: 2-26                      (recursive)               1,048,576\n",
            "├─LSTM: 1-55                             (recursive)               25,190,400\n",
            "├─Attention: 1-56                        (recursive)               --\n",
            "│    └─Linear: 2-27                      (recursive)               1,048,576\n",
            "├─LSTM: 1-57                             (recursive)               25,190,400\n",
            "├─Attention: 1-58                        (recursive)               --\n",
            "│    └─Linear: 2-28                      (recursive)               1,048,576\n",
            "├─LSTM: 1-59                             (recursive)               25,190,400\n",
            "├─Attention: 1-60                        (recursive)               --\n",
            "│    └─Linear: 2-29                      (recursive)               1,048,576\n",
            "├─Dropout: 1-61                          --                        --\n",
            "├─Linear: 1-62                           4,100,000                 4,100,000\n",
            "==========================================================================================\n",
            "Total params: 34,434,976\n",
            "Trainable params: 34,434,976\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 769.13\n",
            "==========================================================================================\n",
            "Input size (MB): 0.14\n",
            "Forward/backward pass size (MB): 1.64\n",
            "Params size (MB): 137.74\n",
            "Estimated Total Size (MB): 139.52\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary of LSTM w/ ATTN ENC\n",
        "print(summary(attn_enc, input_size=(1, 30), dtypes=[torch.long], col_names=(\"num_params\", \"mult_adds\")))\n",
        "\n",
        "# Summary of LSTM w/ ATTN DEC\n",
        "y = torch.randint(0, VOCAB, (1, 29), dtype=torch.long).to(device)\n",
        "h = torch.randn(lstm_layers, 1, lstm_hidden).to(device)\n",
        "c = torch.randn(lstm_layers, 1, lstm_hidden).to(device)\n",
        "hidden = (h, c)\n",
        "enc_outputs = torch.randn(1, 29, lstm_hidden).to(device)\n",
        "print(summary(attn_dec, input_data=(y, hidden, enc_outputs), dtypes=[torch.long], col_names=(\"num_params\", \"mult_adds\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwSfg-7KvA-d",
        "outputId": "66936c12-eb68-4dd3-cae5-d9e66201841a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Param #                   Mult-Adds\n",
            "===============================================================================================\n",
            "TransformerModel                              --                        --\n",
            "├─Embedding: 1-1                              2,048,000                 2,048,000\n",
            "├─PositionalEncoding: 1-2                     --                        --\n",
            "├─Embedding: 1-3                              (recursive)               2,048,000\n",
            "├─PositionalEncoding: 1-4                     --                        --\n",
            "├─TransformerEncoder: 1-5                     --                        --\n",
            "│    └─ModuleList: 2-1                        --                        --\n",
            "│    │    └─TransformerEncoderLayer: 3-1      3,152,384                 2,101,760\n",
            "│    │    └─TransformerEncoderLayer: 3-2      3,152,384                 2,101,760\n",
            "│    │    └─TransformerEncoderLayer: 3-3      3,152,384                 2,101,760\n",
            "│    │    └─TransformerEncoderLayer: 3-4      3,152,384                 2,101,760\n",
            "├─TransformerDecoder: 1-6                     --                        --\n",
            "│    └─ModuleList: 2-2                        --                        --\n",
            "│    │    └─TransformerDecoderLayer: 3-5      4,204,032                 2,102,784\n",
            "│    │    └─TransformerDecoderLayer: 3-6      4,204,032                 2,102,784\n",
            "│    │    └─TransformerDecoderLayer: 3-7      4,204,032                 2,102,784\n",
            "│    │    └─TransformerDecoderLayer: 3-8      4,204,032                 2,102,784\n",
            "├─Linear: 1-7                                 2,052,000                 2,052,000\n",
            "===============================================================================================\n",
            "Total params: 33,525,664\n",
            "Trainable params: 33,525,664\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 22.97\n",
            "===============================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 8.41\n",
            "Params size (MB): 83.67\n",
            "Estimated Total Size (MB): 92.08\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary of Transformer\n",
        "print(summary(trans_model, input_size=[(1, 30), (1, 29)], dtypes=[torch.long, torch.long], col_names=(\"num_params\", \"mult_adds\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZy1zUOrJbFm"
      },
      "source": [
        "### Discussion\n",
        "1.   Compare the final validation losses for three models and provide an explanation of the difference.\n",
        "2.   Discuss which model is the most efficient in terms of computational complexity and translation performance. Give a reason why.\n",
        "3.   Discuss which model is the most efficient in terms of model size and translation performance. Give a reason why.\n",
        "4.   Discuss which model is the most efficient in terms of training time and translation performance. Give a reason why."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02290cc5d3fa427d959ebaafc3a26ab5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03e3343181314d148ee66c2cfd129a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e016fbc8944b4094abec2124f462e1",
            "placeholder": "​",
            "style": "IPY_MODEL_c369cf4e9b314582b40b2b025f4dbff5",
            "value": " 18.5k/18.5k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "06586d26dabb4602aa2a5e4f6f11d125": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "089f8b753a6245999193083b4f0c62eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b4f397d1ac24906861e8c8a673e2557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9e532e9fe945a0af4dcf5a10cb6ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ebd2920396242d1b74b86d9af961501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e9f6c4f42f40a497c6ffb378e74c21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a430f92e48243fbbaff48a2eaccc64e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2af494c0c4a443cbb73a8aaba3c6173c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b380ee21ae94fa1868ca87f68e4cc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30924a03bd6f4beb8bed5fdf95c9a02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bddc306544346b2842938fe990059cd",
              "IPY_MODEL_5948a122d30444538e8c17d649510e87",
              "IPY_MODEL_03e3343181314d148ee66c2cfd129a26"
            ],
            "layout": "IPY_MODEL_36a5b836116b4d8d8874a5ddc02796cb"
          }
        },
        "3214a443a959453ca5d4f01fa6e9f21a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fd73c4887b463eac3e25da0084b113": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a5b836116b4d8d8874a5ddc02796cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38725e2aacb34142b4cbd774d0a833f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7be37ee9859e4d88b809fa96c89cafb0",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d7916922804215b0289af0e2211762",
            "value": " 27.7M/27.7M [00:00&lt;00:00, 133MB/s]"
          }
        },
        "394b6e018cfe4253a13c3ca702213f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07c98d51d2e4469bf46e55b5abb44f4",
            "placeholder": "​",
            "style": "IPY_MODEL_089f8b753a6245999193083b4f0c62eb",
            "value": "Generating train split: 100%"
          }
        },
        "3a2c1e50fc1849e4b53919f09dee9641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7cbcb25477a4a9cbd8aaf76337dc418",
              "IPY_MODEL_96933d2827a6488da37e60b40e5c68ea",
              "IPY_MODEL_f00e49e564d34e2197ad793be3e7e932"
            ],
            "layout": "IPY_MODEL_49ec6d6015464296a6377ce1f03a0548"
          }
        },
        "3b37175d8ed84687af48311580bbaaae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bddc306544346b2842938fe990059cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb98224f6d7f40ceb9968e9c69c2be6a",
            "placeholder": "​",
            "style": "IPY_MODEL_87335e7d2dc54dc897cb2bde1c8aecf9",
            "value": "README.md: 100%"
          }
        },
        "405994a47270432f938906ce19418f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439cb5b8de14477d9d2ef54d0c87eab5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ec6d6015464296a6377ce1f03a0548": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0c28c42b7b4e598a158c40015c7a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "517fa1176e394fb48eafcc1902f23c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53a542222f714fab93b7628db0a32d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e569187696e54602bc2d4d6e7401a249",
            "max": 232825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b12dfe652514490840762b6eab6ef02",
            "value": 232825
          }
        },
        "53e016fbc8944b4094abec2124f462e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c2624e54344e20b573addf3ad08db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "570ee675b2be46b1a2374e96a70acd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_394b6e018cfe4253a13c3ca702213f75",
              "IPY_MODEL_53a542222f714fab93b7628db0a32d05",
              "IPY_MODEL_aa51544e0eb545089cbb26f2aa3e428d"
            ],
            "layout": "IPY_MODEL_21e9f6c4f42f40a497c6ffb378e74c21"
          }
        },
        "5948a122d30444538e8c17d649510e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8330088733e43b1a35896b05e1a8ce6",
            "max": 18506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb033694dc564b0292ae96d905f7936a",
            "value": 18506
          }
        },
        "5db71b45b1b64ecc9d2668c420bab02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61aee6704fb64b538ce6ec7008813ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbd54241c7f4de5b36099d315d55fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca57e7dd6f46414fa1e9eddee2479de7",
            "max": 232825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_517fa1176e394fb48eafcc1902f23c2e",
            "value": 232825
          }
        },
        "7002bfd747ee4ec8a5349e3ce9bd0394": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f83ee82b174bf399f85c50c97518ba",
              "IPY_MODEL_e4ec61c122ea4975bf66113e0f113d35",
              "IPY_MODEL_730506df741d4370889e79004a0769ff"
            ],
            "layout": "IPY_MODEL_405994a47270432f938906ce19418f8b"
          }
        },
        "701991fceb6e448c986f2918a9f49a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730506df741d4370889e79004a0769ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adae496b7890490c9c480281b0620986",
            "placeholder": "​",
            "style": "IPY_MODEL_06586d26dabb4602aa2a5e4f6f11d125",
            "value": " 890/890 [00:00&lt;00:00, 24800.56 examples/s]"
          }
        },
        "77b76e7b2eaa41a09d0a783aba65e094": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff57be8010c544e48efef22204a14272",
              "IPY_MODEL_6dbd54241c7f4de5b36099d315d55fff",
              "IPY_MODEL_c511f4d3a0af44ca9a59600af8f51c12"
            ],
            "layout": "IPY_MODEL_ec7c0083e3624795b7efadf56aba62c7"
          }
        },
        "7b12dfe652514490840762b6eab6ef02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7be37ee9859e4d88b809fa96c89cafb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa49081e1694cc1960e7c1d2ac2903f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf53f6fe1dea49f0be32af13058036e1",
            "max": 27699724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5b5b4b2a6ec4ca6b397cbf83db10b9b",
            "value": 27699724
          }
        },
        "815a63adf5104c4d97037d4d37dfb110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8174ffc4ba7f409ebbfc7f1319c6534d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856b7498bafa420088a71d46db511f36",
            "placeholder": "​",
            "style": "IPY_MODEL_ae8e28ecb72946bfa43c10337200b541",
            "value": "en-fr.zip: 100%"
          }
        },
        "81fcedaf1b56491082add26d5deb2a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f6c93dbea3d42d7a64d69dafae2ef29",
            "max": 8597,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d05b328c3bee4246a9a8b314ad5c053b",
            "value": 8597
          }
        },
        "856b7498bafa420088a71d46db511f36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87335e7d2dc54dc897cb2bde1c8aecf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880cec8ba30d4366b6431575ac0cddcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8174ffc4ba7f409ebbfc7f1319c6534d",
              "IPY_MODEL_7fa49081e1694cc1960e7c1d2ac2903f",
              "IPY_MODEL_38725e2aacb34142b4cbd774d0a833f3"
            ],
            "layout": "IPY_MODEL_a617ef701a3e49f4a5c70aa5ea3818df"
          }
        },
        "88bc08ab551b4855ad6bf2e89702dfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f6c93dbea3d42d7a64d69dafae2ef29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9326b805e3d84661a6e2ca260e6a2620": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96933d2827a6488da37e60b40e5c68ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feded37e56694c148b33e60b3000ad0a",
            "max": 8170,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4c750f21fcb4c98918c5600e3148fe3",
            "value": 8170
          }
        },
        "9b59844aade34471bdda49f7d16c941c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5a306fa5804a7db7b4c40e14072f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b59844aade34471bdda49f7d16c941c",
            "placeholder": "​",
            "style": "IPY_MODEL_2b380ee21ae94fa1868ca87f68e4cc14",
            "value": " 890/890 [00:00&lt;00:00, 22667.65 examples/s]"
          }
        },
        "9e9ca9ffcb2b4998a02c37d4fa9d6437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a617ef701a3e49f4a5c70aa5ea3818df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f4bd66b23a46cdb98749dc523aa66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7950b3d4e7a445ea24f7fd4f49d91e1",
            "placeholder": "​",
            "style": "IPY_MODEL_88bc08ab551b4855ad6bf2e89702dfed",
            "value": "Generating test split: 100%"
          }
        },
        "aa51544e0eb545089cbb26f2aa3e428d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c2624e54344e20b573addf3ad08db6",
            "placeholder": "​",
            "style": "IPY_MODEL_1b9e532e9fe945a0af4dcf5a10cb6ff8",
            "value": " 232825/232825 [00:04&lt;00:00, 64366.94 examples/s]"
          }
        },
        "ab640e0a30f74d0c9a9b05136accdb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8f4bd66b23a46cdb98749dc523aa66d",
              "IPY_MODEL_f9b8cd753c594427a4a529d37ec0d867",
              "IPY_MODEL_e02ab684e49348478c4ee9c3e3756793"
            ],
            "layout": "IPY_MODEL_c3aa19cfc7d440bbb394c79a77881257"
          }
        },
        "acfd79ed58a048c3ad8bdaa000381ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701991fceb6e448c986f2918a9f49a2d",
            "max": 890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c41cc75cba42410fb0b474efff534442",
            "value": 890
          }
        },
        "ad68b86067ea4a7591c42831331f057c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adae496b7890490c9c480281b0620986": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8e28ecb72946bfa43c10337200b541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65dc5ed8f8146718296cf94b1ef941d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe2eb7ab4661409597a6a9a480b203fc",
              "IPY_MODEL_acfd79ed58a048c3ad8bdaa000381ff7",
              "IPY_MODEL_9c5a306fa5804a7db7b4c40e14072f44"
            ],
            "layout": "IPY_MODEL_33fd73c4887b463eac3e25da0084b113"
          }
        },
        "b7950b3d4e7a445ea24f7fd4f49d91e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b795e0e446bd47cd8a130c9b0e23d9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3f43949c6ca4c15affd611a77977737",
              "IPY_MODEL_81fcedaf1b56491082add26d5deb2a5e",
              "IPY_MODEL_ebb527fdd1f448f0abfac5be53d8e1ea"
            ],
            "layout": "IPY_MODEL_3214a443a959453ca5d4f01fa6e9f21a"
          }
        },
        "bded9004353647c8bb34a05e3ce9646e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be7cc6c6817143e1a36431adc6e59515": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c369cf4e9b314582b40b2b025f4dbff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3aa19cfc7d440bbb394c79a77881257": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41cc75cba42410fb0b474efff534442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c511f4d3a0af44ca9a59600af8f51c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61aee6704fb64b538ce6ec7008813ce5",
            "placeholder": "​",
            "style": "IPY_MODEL_bded9004353647c8bb34a05e3ce9646e",
            "value": " 232825/232825 [00:03&lt;00:00, 65484.42 examples/s]"
          }
        },
        "c9efc83274a843ed881e441a7f78437b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca57e7dd6f46414fa1e9eddee2479de7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb033694dc564b0292ae96d905f7936a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf53f6fe1dea49f0be32af13058036e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05b328c3bee4246a9a8b314ad5c053b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4c750f21fcb4c98918c5600e3148fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5b5b4b2a6ec4ca6b397cbf83db10b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7cbcb25477a4a9cbd8aaf76337dc418": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be7cc6c6817143e1a36431adc6e59515",
            "placeholder": "​",
            "style": "IPY_MODEL_5db71b45b1b64ecc9d2668c420bab02c",
            "value": "iwslt2017.py: 100%"
          }
        },
        "d8330088733e43b1a35896b05e1a8ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b847bb07594782a74372d4a050b1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd7fc2c0f90146d18b03d8451abb765d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e02ab684e49348478c4ee9c3e3756793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af494c0c4a443cbb73a8aaba3c6173c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd7fc2c0f90146d18b03d8451abb765d",
            "value": " 8597/8597 [00:00&lt;00:00, 42428.59 examples/s]"
          }
        },
        "e171ae98748241708fe219f825257fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ec61c122ea4975bf66113e0f113d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ba4986b3bf4fd7bc46a33419e1eaae",
            "max": 890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_815a63adf5104c4d97037d4d37dfb110",
            "value": 890
          }
        },
        "e569187696e54602bc2d4d6e7401a249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f83ee82b174bf399f85c50c97518ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a430f92e48243fbbaff48a2eaccc64e",
            "placeholder": "​",
            "style": "IPY_MODEL_4b0c28c42b7b4e598a158c40015c7a43",
            "value": "Generating validation split: 100%"
          }
        },
        "ebb527fdd1f448f0abfac5be53d8e1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02290cc5d3fa427d959ebaafc3a26ab5",
            "placeholder": "​",
            "style": "IPY_MODEL_c9efc83274a843ed881e441a7f78437b",
            "value": " 8597/8597 [00:00&lt;00:00, 43868.15 examples/s]"
          }
        },
        "ec7c0083e3624795b7efadf56aba62c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef44c969839f49948887aa8e069e73d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00e49e564d34e2197ad793be3e7e932": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad68b86067ea4a7591c42831331f057c",
            "placeholder": "​",
            "style": "IPY_MODEL_1b4f397d1ac24906861e8c8a673e2557",
            "value": " 8.17k/8.17k [00:00&lt;00:00, 787kB/s]"
          }
        },
        "f07c98d51d2e4469bf46e55b5abb44f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f43949c6ca4c15affd611a77977737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439cb5b8de14477d9d2ef54d0c87eab5",
            "placeholder": "​",
            "style": "IPY_MODEL_1ebd2920396242d1b74b86d9af961501",
            "value": "Generating test split: 100%"
          }
        },
        "f5ba4986b3bf4fd7bc46a33419e1eaae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d7916922804215b0289af0e2211762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9b8cd753c594427a4a529d37ec0d867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9326b805e3d84661a6e2ca260e6a2620",
            "max": 8597,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8b847bb07594782a74372d4a050b1ef",
            "value": 8597
          }
        },
        "fb98224f6d7f40ceb9968e9c69c2be6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2eb7ab4661409597a6a9a480b203fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef44c969839f49948887aa8e069e73d7",
            "placeholder": "​",
            "style": "IPY_MODEL_9e9ca9ffcb2b4998a02c37d4fa9d6437",
            "value": "Generating validation split: 100%"
          }
        },
        "feded37e56694c148b33e60b3000ad0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff57be8010c544e48efef22204a14272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b37175d8ed84687af48311580bbaaae",
            "placeholder": "​",
            "style": "IPY_MODEL_e171ae98748241708fe219f825257fb8",
            "value": "Generating train split: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
